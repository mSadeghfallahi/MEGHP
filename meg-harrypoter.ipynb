{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12502068,"sourceType":"datasetVersion","datasetId":7890451,"isSourceIdPinned":false},{"sourceId":12558910,"sourceType":"datasetVersion","datasetId":7921384}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Loading Data","metadata":{}},{"cell_type":"code","source":"import os\n\nfor dirname, _, filenames in os.walk('../input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:00:58.663986Z","iopub.execute_input":"2025-07-24T01:00:58.664673Z","iopub.status.idle":"2025-07-24T01:00:58.680163Z","shell.execute_reply.started":"2025-07-24T01:00:58.664640Z","shell.execute_reply":"2025-07-24T01:00:58.679349Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nfor dirname, _, filenames in os.walk('../working/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:00:58.680913Z","iopub.execute_input":"2025-07-24T01:00:58.681179Z","iopub.status.idle":"2025-07-24T01:00:58.698077Z","shell.execute_reply.started":"2025-07-24T01:00:58.681151Z","shell.execute_reply":"2025-07-24T01:00:58.697421Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport sys\nimport time\nimport re\nimport string\nimport pickle\nimport copy\n\nimport numpy as np\nfrom numpy.linalg import inv\n\nimport torch\n# import pandas as pd\nfrom collections import Counter\n\nfrom scipy.stats import zscore\nimport scipy.io as sio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:00:58.698826Z","iopub.execute_input":"2025-07-24T01:00:58.699030Z","iopub.status.idle":"2025-07-24T01:01:01.072551Z","shell.execute_reply.started":"2025-07-24T01:00:58.699013Z","shell.execute_reply":"2025-07-24T01:01:01.071564Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class HP_dataset_denoised(torch.utils.data.Dataset):\n\tdef __init__(self,args):\n\t\tself.args = args\n\n\t\tself.all_texts, self.all_megs = self.load_words_and_megs()\n\n\t\tself.uniq_words = self.get_uniq_words()\n\t\tself.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n\t\tself.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n\n\t\tself.texts, self.megs = self.load_data()\n\n\tdef load_words_and_megs(self, do_zscore = True):\n\t\tif self.args.chapter==1:\n\t\t\tmat = sio.loadmat(self.args.base_data_path+\"A_HP_notDetrended_25ms.mat\")\n\t\t\twords = mat['labels']\n\t\t\tall_texts=[w[0][0].replace(\"@\",\"\").replace(\"\\\\\",\"\").replace(\"+\",\"\").replace(\"^\",\"\").strip() for w in words][:5176]\n\t\t\t\n\t\t\tall_megs=np.load(self.args.base_data_path+\"denoised_HP.npy\")\n\t\t\tall_megs=np.swapaxes(all_megs,1,2)\n\t\telif self.args.chapter==2:\n\t\t\twords = np.load(self.args.base_data_path+\"words_chapter_2.npy\")\n\t\t\tall_texts=[w.replace(\"@\",\"\").replace(\"\\\\\",\"\").replace(\"+\",\"\").replace(\"^\",\"\").strip() for w in words]\n\t\t\t\n\t\t\tall_megs=np.load(self.args.base_data_path+\"denoised_HP_chapter2.npy\")\n\t\t\tall_megs=np.swapaxes(all_megs,1,2)\n\n\t\tif do_zscore:\n\t\t\tall_megs = zscore(all_megs)\n\n\t\treturn all_texts, all_megs\n\n\tdef load_data(self):\n\t\ttexts_to_load=list()\n\t\tmegs_to_load=list()\n\t\t\n\t\tmegs=np.mean(self.all_megs[:,:,12:17],axis=2)\n\t\tfor location in range(self.args.sequence_length,len(self.all_texts)):\n\t\t\ttexts=self.all_texts[location-self.args.sequence_length+1:location+1]\n\t\t\ttexts_to_load.append([self.word_to_index[w] for w in texts])\n\t\t\tmegs_to_load.append(megs[location])\n\t\t\n\t\ttexts_to_load=np.vstack(texts_to_load)\n\t\tmegs_to_load=np.vstack(megs_to_load)\n\t\tassert len(texts_to_load)==len(megs_to_load)\n\t\treturn texts_to_load, megs_to_load\n\n\tdef get_uniq_words(self):\n\t\twords=set()\n\t\tfor word in self.all_texts:\n\t\t\twords.add(word)\n\t\treturn list(words)\n\n\tdef __len__(self):\n\t\treturn len(self.texts) \n\n\tdef __getitem__(self, index):\n\t\t# return word, meg\n\t\treturn(\n\t\t\ttorch.tensor(self.texts[index]),\n\t\t\ttorch.tensor(self.megs[index+self.args.meg_offset])\n\t\t)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:01:01.075099Z","iopub.execute_input":"2025-07-24T01:01:01.075437Z","iopub.status.idle":"2025-07-24T01:01:01.087645Z","shell.execute_reply.started":"2025-07-24T01:01:01.075416Z","shell.execute_reply":"2025-07-24T01:01:01.086632Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfrom scipy.special import softmax\nfrom scipy.stats import pearsonr\nfrom scipy.stats import chi2\n\nfrom sklearn.model_selection import KFold\n\nimport statsmodels.stats.multitest as smm\n\nimport torch\n\nimport mne\nfrom mne.io import read_raw_ctf\n\n# from utils.ridge.ridge import bootstrap_ridge","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:01:01.088375Z","iopub.execute_input":"2025-07-24T01:01:01.088645Z","iopub.status.idle":"2025-07-24T01:01:01.964519Z","shell.execute_reply.started":"2025-07-24T01:01:01.088626Z","shell.execute_reply":"2025-07-24T01:01:01.963423Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\ndef correlation_loss_wordwise(x,y):\n\treturn correlation_loss(x,y,'wordwise')\n\ndef correlation_loss_channelwise(x,y):\n\treturn correlation_loss(x,y,'channelwise')\n\ndef correlation_loss(x,y,mode):\n\tcorr_list=correlation(x,y,mode)\n\treturn -torch.mean(corr_list) # because we want to minimize loss/maximize correlation\n\ndef correlation(x,y,mode=\"channelwise\"):\n\tvalide_modes={'channelwise','wordwise'}\n\tif mode not in valide_modes:\n\t\traise ValueError(\"Unknown Correlation Loss Function.\")\n\n\tif isinstance(x, np.ndarray) and isinstance(y, np.ndarray):\n\t\tx=torch.tensor(x)\n\t\ty=torch.tensor(y)\n\t\n\t# if channelwise correlation\n\txx=x.reshape(-1,x.shape[-1])\n\tyy=y.reshape(-1,y.shape[-1])\n\t# if wordwise correlation\n\tif mode==\"wordwise\":\n\t\txx=xx.transpose(0, 1)\n\t\tyy=yy.transpose(0, 1)\n\t\t\n\t# print(xx.shape,yy.shape)\n\t# print(torch.mean(xx,axis=0).shape,torch.mean(yy,axis=0).shape)\n\tvx = xx - torch.mean(xx,axis=0)\n\tvy = yy - torch.mean(yy,axis=0)\n\t# print(torch.sum(vx * vy, dim=0).shape)\n\tcor_list=torch.sum(vx * vy, dim=0) * torch.rsqrt(torch.sum(vx ** 2,dim=0)) * torch.rsqrt(torch.sum(vy ** 2,dim=0))\n\t# print(cor_list.shape, cor_list)\n\treturn cor_list\n\ndef compute_brain_surprisal_according_to_polarity(brain_data,neg_sig_channels=None,pos_sig_channels=None):\n\t# brain_data: N_data_point x N_channel\n\tif neg_sig_channels and pos_sig_channels:\n\t\ttemp1=-brain_data[:,neg_sig_channels]\n\t\ttemp2=brain_data[:,pos_sig_channels]\n\t\ttemp=np.hstack([temp1,temp2])\n\t\treturn np.mean(temp,axis=1)\n\telse:\n\t\treturn np.mean(brain_data,axis=1)\n\ndef load_tokenizer_and_model_from_transformers(name):\n\tif name==\"GPT-J\":\n\t\tfrom transformers import AutoTokenizer, GPTJForCausalLM\n\t\ttokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\",truncation_side=\"left\",padding_side=\"left\")\n\t\tmodel = GPTJForCausalLM.from_pretrained(\"EleutherAI/gpt-j-6B\",output_hidden_states=True)\n\telif name==\"demo_GPT\":\n\t\tfrom transformers import AutoTokenizer, GPTJForCausalLM\n\t\ttokenizer = AutoTokenizer.from_pretrained(\"hf-internal-testing/tiny-random-gptj\",truncation_side=\"left\",padding_side=\"left\")\n\t\tmodel = GPTJForCausalLM.from_pretrained(\"hf-internal-testing/tiny-random-gptj\",output_hidden_states=True)\t\n\telif name==\"GPT2\":\n\t\tfrom transformers import AutoTokenizer, GPT2LMHeadModel\n\t\ttokenizer = AutoTokenizer.from_pretrained(\"gpt2\",truncation_side=\"left\",padding_side=\"left\")\n\t\tmodel = GPT2LMHeadModel.from_pretrained(\"gpt2\",output_hidden_states=True)\n\telif name==\"GPT2-xl\":\n\t\tfrom transformers import AutoTokenizer, GPT2LMHeadModel\n\t\ttokenizer = AutoTokenizer.from_pretrained(\"gpt2-xl\",truncation_side=\"left\",padding_side=\"left\")\n\t\tmodel = GPT2LMHeadModel.from_pretrained(\"gpt2-xl\",output_hidden_states=True)\n\telif name==\"GPT-Neo\":\n\t\tfrom transformers import AutoTokenizer, GPTNeoForCausalLM\n\t\ttokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-2.7B\",truncation_side=\"left\",padding_side=\"left\")\n\t\tmodel = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-2.7B\",output_hidden_states=True)\t\n\telif name==\"Llama-2\":\n\t\tfrom transformers import AutoTokenizer, LlamaForCausalLM\n\t\ttokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\",truncation_side=\"left\",padding_side=\"left\")\n\t\tmodel = LlamaForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-hf\",output_hidden_states=True)\t\n\telif name==\"GPT-J_bare\":\n\t\tfrom transformers import AutoTokenizer, GPTJModel\n\t\ttokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\",truncation_side=\"left\",padding_side=\"left\")\n\t\tmodel = GPTJModel.from_pretrained(\"EleutherAI/gpt-j-6B\")\n\telif name==\"demo_GPT_bare\":\n\t\tfrom transformers import AutoTokenizer, GPTJModel\n\t\ttokenizer = AutoTokenizer.from_pretrained(\"hf-internal-testing/tiny-random-gptj\",truncation_side=\"left\",padding_side=\"left\")\n\t\tmodel = GPTJModel.from_pretrained(\"hf-internal-testing/tiny-random-gptj\")\n\telif name==\"GPT2_bare\":\n\t\tfrom transformers import GPT2Tokenizer, GPT2Model\n\t\ttokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\",truncation_side=\"left\",padding_side=\"left\")\n\t\tmodel = GPT2Model.from_pretrained(\"gpt2\")\n\telif name==\"GPT2-xl_bare\":\n\t\tfrom transformers import GPT2Tokenizer, GPT2Model\n\t\ttokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-xl\",truncation_side=\"left\",padding_side=\"left\")\n\t\tmodel = GPT2Model.from_pretrained(\"gpt2-xl\")\n\telif name==\"GPT-Neo_bare\":\n\t\tfrom transformers import AutoTokenizer, GPTNeoModel\n\t\ttokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-2.7B\",truncation_side=\"left\",padding_side=\"left\")\n\t\tmodel = GPTNeoModel.from_pretrained(\"EleutherAI/gpt-neo-2.7B\")\n\telif name==\"Llama-2_bare\":\n\t\tfrom transformers import AutoTokenizer, LlamaModel\n\t\ttokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\",truncation_side=\"left\",padding_side=\"left\")\n\t\tmodel = LlamaModel.from_pretrained(\"meta-llama/Llama-2-7b-hf\")\n\telse:\n\t\traise ValueError(\"Unknown model name.\")\n\treturn tokenizer, model\n\ndef find_indices_of_last_word(tokenizer,last_word,encodings):\n\tfor word_end in range(len(encodings)-1,-1,-1):\n\t\tfor word_start in range(word_end,-1,-1):\n\t\t\treconstructed=\"\".join([tokenizer.decode(i) for i in encodings[word_start:word_end+1]]).strip()\n\t\t\tif reconstructed==last_word:\n\t\t\t\treturn (word_start, word_end)\n\treturn (len(encodings)-1,len(encodings)-1)\n\ndef find_indices_of_last_word_in_batch(tokenizer,batch_last_words,batch_encodings):\n\tassert len(batch_last_words)==len(batch_encodings)\n\treturn [find_indices_of_last_word(tokenizer,last_word,encodings) for last_word,encodings in zip(batch_last_words,batch_encodings)]\n\ndef compute_surprisal(all_last_words,all_logits):    \n\tassert len(all_logits)==len(all_last_words)\n\tall_surprisal=list()\n\tfor token_ids, logits in zip(all_last_words,all_logits):\n\t\tassert len(token_ids)==len(logits)\n\t\tsurprisal=0\n\t\tfor token_id,logit in zip(token_ids,logits):\n\t\t\tp=softmax(logit)\n\t\t\tsurprisal+=-1*np.log(p[token_id])\n\t\tall_surprisal.append(surprisal)\n\treturn all_surprisal\n\ndef ceiling_division(n, d):\n\treturn -(n // -d)\n\ndef delay_one(mat, d):\n    # delays a matrix by a delay d. Positive d ==> row t has row t-d\n    new_mat = np.zeros_like(mat)\n    if d > 0:\n        new_mat[d:] = mat[:-d]\n    elif d < 0:\n        new_mat[:d] = mat[-d:]\n    else:\n        new_mat = mat\n    return new_mat\n\n\ndef delay_mat(mat, delays):\n    # delays a matrix by a set of delays d.\n    # a row t in the returned matrix has the concatenated:\n    # row(t-delays[0],t-delays[1]...t-delays[last] )\n    new_mat = np.concatenate([delay_one(mat, d) for d in delays], axis=-1)\n    return new_mat\n\n###############################\ndef Fisher_method(all_pvalues):\n\tchi=list()\n\tchi_pvalues=list()\n\tfor pvalues in all_pvalues.T:\n\t\tchi_squared=-2*np.sum([np.log(p) for p in pvalues])\n\t\tchi_p=chi2.sf(chi_squared,2*len(pvalues))\n\t\tchi.append(chi_squared)\n\t\tchi_pvalues.append(chi_p)\n\treturn np.array(chi),np.array(chi_pvalues)\n\ndef do_ridge_regression(features,brain_responses,n_splits=10):\n\tkf = KFold(n_splits=n_splits)\n\n\tbrain_responses_pred=np.zeros(brain_responses.shape)\n\tfor train, test in kf.split(features):\n\t\tX_train, X_test, y_train, y_test = features[train], features[test], brain_responses[train], brain_responses[test]\n\n\t\talphas = np.logspace(-1, 2, 2) # Equally log-spaced alphas between the first number and the second number. The third number is the number of alphas to test.\n\t\tnboots = 1 # Number of cross-validation runs.\n\t\tchunklen = 40 # \n\t\tnchunks = 20\n\n\t\twt, corr, alphas, bscorrs, valinds = bootstrap_ridge(X_train, y_train, X_test, y_test,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\talphas, nboots, chunklen, nchunks,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsingcutoff=1e-10, single_alpha=True)\n\t\ty_test_pred = np.dot(X_test, wt)\n\n\t\t# fill prediction in the correct position\n\t\tfor i,word_idx in enumerate(test):\n\t\t\tbrain_responses_pred[word_idx] = y_test_pred[i]\n\n\treturn brain_responses_pred\n\ndef cosine_similarity(A,B):\n\treturn np.dot(A,B)/(np.linalg.norm(A)*np.linalg.norm(B))\n\n\ndef perm_test(D,P1,P2,n=1000):\n\tmat=np.zeros((D.shape[2],D.shape[0]))\n\tfor ch in range(D.shape[2]):\n\t\tprint(ch,\"...\")\n\t\tfor t in range(D.shape[0]):\n\t\t\tdiff_true=pearsonr(D[t,:,ch], P1[t,:,ch])[0] - pearsonr(D[t,:,ch], P2[t,:,ch])[0]\n\t\t\tdiff_list=list()\n\t\t\tfor i in range(n):\n\t\t\t\tD_i=np.random.permutation(D[t,:,ch])\n\t\t\t\tdiff_i=pearsonr(D_i, P1[t,:,ch])[0] - pearsonr(D_i, P2[t,:,ch])[0]\n\t\t\t\tdiff_list.append(diff_i)\n\t\t\tp_value=(np.sum([item>diff_true for item in diff_list])+1)/(len(diff_list)+1)\n\t\t\tmat[ch,t]=p_value\n\treturn mat\n\ndef FDR_correction(pvals):\n\tpvals=np.array(pvals)\n\tif len(pvals.shape)>1:\n\t\tpvals_reshape=np.reshape(pvals,np.product(pvals.shape))\n\telse:\n\t\tpvals_reshape=pvals\n\tpvals_corrected=smm.fdrcorrection(pvals_reshape)[1]\n\tpvals_corrected=np.reshape(pvals_corrected,pvals.shape)\n\treturn pvals_corrected\n###############################\n\ndef plot_meg_to_cortex(sensor_file, corrs, fig, ax, file=False, trim_sensor=True):\n\t\"\"\"\n\tsensor_file: a file that has all information about MEG\n\tcorr_file: (path to a file containing) correlations of channels\n\t\"\"\"\n\n\traw_fname = os.path.join(sensor_file)\n\traw = read_raw_ctf(raw_fname,verbose=False)\n\n\t# drop suffix\n\tif trim_sensor:\n\t\tnew_channel_names=dict()\n\t\tfor name in raw.info['ch_names']:\n\t\t\tnew_name=name.split(\"-\")[0]\n\t\t\tnew_channel_names[name]=new_name\n\t\t\n\t\traw.rename_channels(new_channel_names,verbose=False)\n\t\n\ttemp=mne.channel_indices_by_type(raw.info)\n\tmag_info=mne.pick_info(raw.info,temp['mag'])\n\n\tif file:\n\t\tcorrs=pickle.load(open(corrs,\"rb\"))\n\t# print(np.mean(corrs))\n\n\t# im,cm=mne.viz.plot_topomap(corrs,mag_info,show=False,sphere=0.2,axes=ax)\n\tim,cm=mne.viz.plot_topomap(corrs,mag_info,show=False,axes=ax)\n\n\t# manually fiddle the position of colorbar\n\tax_x_start = 0.95\n\tax_x_width = 0.04\n\tax_y_start = 0.1\n\tax_y_height = 0.9\n\tcbar_ax = fig.add_axes([ax_x_start, ax_y_start, ax_x_width, ax_y_height])\n\tclb = fig.colorbar(im, cax=cbar_ax)\n\ndef plot_meg_to_cortex_multiple(sensor_file, corrs_list, fig, axes, file=False, trim_sensor=True):\n\t\"\"\"\n\tsensor_file: a file that has all information about MEG\n\tcorr_file: (path to a file containing) correlations of channels\n\t\"\"\"\n\n\traw_fname = os.path.join(sensor_file)\n\traw = read_raw_ctf(raw_fname,verbose=False)\n\n\t# drop suffix\n\tif trim_sensor:\n\t\tnew_channel_names=dict()\n\t\tfor name in raw.info['ch_names']:\n\t\t\tnew_name=name.split(\"-\")[0]\n\t\t\tnew_channel_names[name]=new_name\n\t\t\n\t\traw.rename_channels(new_channel_names,verbose=False)\n\t\n\ttemp=mne.channel_indices_by_type(raw.info)\n\tmag_info=mne.pick_info(raw.info,temp['mag'])\n\n\tif file:\n\t\tcorrs=pickle.load(open(corrs,\"rb\"))\n\t# print(np.mean(corrs))\n\n\tassert len(corrs_list)==axes\n\n\tfor i,ax in enumerate(axes):\n\t\tim,cm=mne.viz.plot_topomap(corrs,mag_info,show=False,axes=axes)\n\n\t# manually fiddle the position of colorbar\n\tax_x_start = 0.95\n\tax_x_width = 0.04\n\tax_y_start = 0.1\n\tax_y_height = 0.9\n\tcbar_ax = fig.add_axes([ax_x_start, ax_y_start, ax_x_width, ax_y_height])\n\tclb = fig.colorbar(im, cax=cbar_ax)\n\n\n# def load_glove(file_path):\n# \t\"\"\"\n# \tfile_path: a txt file that stores glove embeddings\n\t\n# \tReturns\n# \tvocab_npa: all words\n# \tembs_npa: a matrix that contains embeddings of words in the same order as vocab_npa\n# \t\"\"\"\n# \tvocab,embeddings = [],[]\n\t\n# \twith open(file_path,'rt') as fi:\n# \t\tfull_content = fi.read().strip().split('\\n')\n\t\n# \tfor i in range(len(full_content)):\n# \t\ti_word = full_content[i].split(' ')[0]\n# \t\ti_embeddings = [float(val) for val in full_content[i].split(' ')[1:]]\n# \t\tvocab.append(i_word)\n# \t\tembeddings.append(i_embeddings)\n\t\n# \tvocab_npa = np.array(vocab)\n# \tembs_npa = np.array(embeddings)\n\n# \t#insert '<pad>' and '<unk>' tokens at start of vocab_npa.\n# \tvocab_npa = np.insert(vocab_npa, 0, '<pad>')\n# \tvocab_npa = np.insert(vocab_npa, 1, '<unk>')\n# \t#print(vocab_npa[:10])\n\n# \tpad_emb_npa = np.zeros((1,embs_npa.shape[1]))   #embedding for '<pad>' token.\n# \tunk_emb_npa = np.mean(embs_npa,axis=0,keepdims=True)    #embedding for '<unk>' token.\n\n# \t#insert embeddings for pad and unk tokens at top of embs_npa.\n# \tembs_npa = np.vstack((pad_emb_npa,unk_emb_npa,embs_npa))\n# \t#print(embs_npa.shape)\n\n# \treturn vocab_npa, embs_npa","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:01:01.965567Z","iopub.execute_input":"2025-07-24T01:01:01.965979Z","iopub.status.idle":"2025-07-24T01:01:02.003561Z","shell.execute_reply.started":"2025-07-24T01:01:01.965955Z","shell.execute_reply":"2025-07-24T01:01:02.002739Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#import scipy.stats\nimport random\ndef zscore(mat, return_unzvals=False):\n    \"\"\"Z-scores the rows of [mat] by subtracting off the mean and dividing\n    by the standard deviation.\n    If [return_unzvals] is True, a matrix will be returned that can be used\n    to return the z-scored values to their original state.\n    \"\"\"\n    zmat = np.empty(mat.shape, mat.dtype)\n    unzvals = np.zeros((zmat.shape[0], 2), mat.dtype)\n    for ri in range(mat.shape[0]):\n        unzvals[ri,0] = np.std(mat[ri,:])\n        unzvals[ri,1] = np.mean(mat[ri,:])\n        zmat[ri,:] = (mat[ri,:]-unzvals[ri,1]) / (1e-10+unzvals[ri,0])\n    \n    if return_unzvals:\n        return zmat, unzvals\n    \n    return zmat\n\ndef center(mat, return_uncvals=False):\n    \"\"\"Centers the rows of [mat] by subtracting off the mean, but doesn't \n    divide by the SD.\n    Can be undone like zscore.\n    \"\"\"\n    cmat = np.empty(mat.shape)\n    uncvals = np.ones((mat.shape[0], 2))\n    for ri in range(mat.shape[0]):\n        uncvals[ri,1] = np.mean(mat[ri,:])\n        cmat[ri,:] = mat[ri,:]-uncvals[ri,1]\n    \n    if return_uncvals:\n        return cmat, uncvals\n    \n    return cmat\n\ndef unzscore(mat, unzvals):\n    \"\"\"Un-Z-scores the rows of [mat] by multiplying by unzvals[:,0] (the standard deviations)\n    and then adding unzvals[:,1] (the row means).\n    \"\"\"\n    unzmat = np.empty(mat.shape)\n    for ri in range(mat.shape[0]):\n        unzmat[ri,:] = mat[ri,:]*(1e-10+unzvals[ri,0])+unzvals[ri,1]\n    return unzmat\n\ndef ridge(A, b, alpha):\n    \"\"\"Performs ridge regression, estimating x in Ax=b with a regularization\n    parameter of alpha.\n    With $G=\\alpha I(m_A)$, this function returns $W$ with:\n    $W=(A^TA+G^TG)^{-1}A^Tb^T$\n    Tantamount to minimizing $||Ax-b||+||\\alpha I||$.\n    \"\"\"\n    G = np.matrix(np.identity(A.shape[1]) * alpha)\n    return np.dot(np.dot(np.linalg.inv(np.dot(A.T,A) + np.dot(G.T,G)), A.T), b.T)\n\ndef model_voxels(Rstim, Pstim, Rresp, Presp, alpha):\n    \"\"\"Use ridge regression with regularization parameter [alpha] to model [Rresp]\n    using [Rstim].  Correlation coefficients on the test set ([Presp] and [Pstim])\n    will be returned for each voxel, as well as the linear weights.\n    \"\"\"\n    print (\"Z-scoring stimuli (with a flip)... (or not)\")\n    #zRstim = zscore(Rstim.T).T\n    #zPstim = zscore(Pstim.T).T\n    \n    Rresp[np.isnan(Rresp)] = 0.0\n    Presp[np.isnan(Presp)] = 0.0\n    \n    print (\"Running ridge regression...\")\n    rwts = ridge(Rstim, Rresp.T, alpha)\n    print (\"Finding correlations...\")\n    pred = np.dot(Pstim, rwts)\n    prednorms = np.apply_along_axis(np.linalg.norm, 0, pred)\n    respnorms = np.apply_along_axis(np.linalg.norm, 0, Presp)\n    correlations = np.array(np.sum(np.multiply(Presp, pred), 0)).squeeze()/(prednorms*respnorms)\n    \n    print (\"Max correlation: %0.3f\" % np.max(correlations))\n    print (\"Skewness: %0.3f\" % scipy.stats.skew(correlations))\n    return np.array(correlations), rwts\n\ndef model_voxels_old(Rstim, Pstim, Rresp, Presp, alpha):\n    \"\"\"Use ridge regression with regularization parameter [alpha] to model [Rresp]\n    using [Rstim].  Correlation coefficients on the test set ([Presp] and [Pstim])\n    will be returned for each voxel, as well as the linear weights.\n    \"\"\"\n    print (\"Z-scoring stimuli (with a flip)...\")\n    #zRstim = zscore(Rstim.T).T\n    #zPstim = zscore(Pstim.T).T\n    \n    Rresp[np.isnan(Rresp)] = 0.0\n    Presp[np.isnan(Presp)] = 0.0\n    \n    print (\"Running ridge regression...\")\n    rwts = ridge(Rstim, Rresp.T, alpha)\n    print (\"Finding correlations...\")\n    correlations = []\n    for vi in range(Presp.shape[1]):\n        rcorr = np.corrcoef(Presp[:,vi].T,np.array((np.matrix(Pstim) * np.matrix(rwts[:,vi]))).T)[0,1]\n        correlations.append(rcorr)\n        \n    print (\"Max correlation: %0.3f\" % np.max(correlations))\n    print (\"Skewness: %0.3f\" % scipy.stats.skew(correlations))\n    return np.array(correlations), rwts\n\ndef gaussianize(vec):\n    \"\"\"Uses a look-up table to force the values in [vec] to be gaussian.\"\"\"\n    ranks = np.argsort(np.argsort(vec))\n    cranks = (ranks+1).astype(float)/(ranks.max()+2)\n    vals = scipy.stats.norm.isf(1-cranks)\n    zvals = vals/vals.std()\n    return zvals\n\ndef gaussianize_mat(mat):\n    \"\"\"Gaussianizes each column of [mat].\"\"\"\n    gmat = np.empty(mat.shape)\n    for ri in range(mat.shape[1]):\n        gmat[:,ri] = gaussianize(mat[:,ri])\n    return gmat\n\ndef make_delayed(stim, delays, circpad=False):\n    \"\"\"Creates non-interpolated concatenated delayed versions of [stim] with the given [delays] \n    (in samples).\n    \n    If [circpad], instead of being padded with zeros, [stim] will be circularly shifted.\n    \"\"\"\n    nt,ndim = stim.shape\n    dstims = []\n    for di,d in enumerate(delays):\n        dstim = np.zeros((nt, ndim))\n        if d<0: ## negative delay\n            dstim[:d,:] = stim[-d:,:]\n            if circpad:\n                dstim[d:,:] = stim[:-d,:]\n        elif d>0:\n            dstim[d:,:] = stim[:-d,:]\n            if circpad:\n                dstim[:d,:] = stim[-d:,:]\n        else: ## d==0\n            dstim = stim.copy()\n        dstims.append(dstim)\n    return np.hstack(dstims)\n\ndef mult_diag(d, mtx, left=True):\n    \"\"\"Multiply a full matrix by a diagonal matrix.\n    This function should always be faster than dot.\n\n    Input:\n      d -- 1D (N,) array (contains the diagonal elements)\n      mtx -- 2D (N,N) array\n\n    Output:\n      mult_diag(d, mts, left=True) == dot(diag(d), mtx)\n      mult_diag(d, mts, left=False) == dot(mtx, diag(d))\n    \n    By Pietro Berkes\n    From http://mail.scipy.org/pipermail/numpy-discussion/2007-March/026807.html\n    \"\"\"\n    if left:\n        return (d*mtx.T).T\n    else:\n        return d*mtx\n\nimport time\nimport logging\ndef counter(iterable, countevery=100, total=None, logger=logging.getLogger(\"counter\")):\n    \"\"\"Logs a status and timing update to [logger] every [countevery] draws from [iterable].\n    If [total] is given, log messages will include the estimated time remaining.\n    \"\"\"\n    start_time = time.time()\n\n    ## Check if the iterable has a __len__ function, use it if no total length is supplied\n    if total is None:\n        if hasattr(iterable, \"__len__\"):\n            total = len(iterable)\n    \n    for count, thing in enumerate(iterable):\n        yield thing\n        \n        if not count%countevery:\n            current_time = time.time()\n            rate = float(count+1)/(current_time-start_time)\n\n            if rate>1: ## more than 1 item/second\n                ratestr = \"%0.2f items/second\"%rate\n            else: ## less than 1 item/second\n                ratestr = \"%0.2f seconds/item\"%(rate**-1)\n            \n            if total is not None:\n                remitems = total-(count+1)\n                remtime = remitems/rate\n                timestr = \", %s remaining\" % time.strftime('%H:%M:%S', time.gmtime(remtime))\n                itemstr = \"%d/%d\"%(count+1, total)\n            else:\n                timestr = \"\"\n                itemstr = \"%d\"%(count+1)\n\n            formatted_str = \"%s items complete (%s%s)\"%(itemstr,ratestr,timestr)\n            if logger is None:\n                print (formatted_str)\n            else:\n                logger.info(formatted_str)\n\n\ndef wait_for_disk(dir, maxtime=0.2, retrytime=10.0, maxtries=100):\n    \"\"\"Waits to continue until disk is not slammed.\n    \"\"\"\n    for trynum in range(maxtries):\n        stime = time.time()\n        os.listdir(dir)\n        lstime = time.time() - stime\n        if lstime < maxtime:\n            print (\"Disk access is quick (%0.3f seconds to ls), continuing..\" % lstime)\n            return\n        else:\n            print (\"Disk access is slow (%0.3f seconds to ls), waiting more..\" % lstime)\n            time.sleep(retrytime)\n\n    print (\"Disk access is slow but I'm starting anyway..\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:01:02.004770Z","iopub.execute_input":"2025-07-24T01:01:02.005023Z","iopub.status.idle":"2025-07-24T01:01:02.037541Z","shell.execute_reply.started":"2025-07-24T01:01:02.004994Z","shell.execute_reply":"2025-07-24T01:01:02.036644Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Ridge Correlation","metadata":{}},{"cell_type":"code","source":"#import scipy\nfrom functools import reduce\nimport logging\n# from .utils import mult_diag, counter\nimport random\nimport itertools as itools\n\nzs = lambda v: (v-v.mean(0))/v.std(0) ## z-score function\n\n\ndef ridge_corr(Rstim, Pstim, Rresp, Presp, alphas, normalpha=False, dtype=np.single, corrmin=0.2,\n               singcutoff=1e-10, use_corr=True, logger=logging.getLogger(\"ridge_corr\")):\n    \"\"\"Uses ridge regression to find a linear transformation of [Rstim] that approximates [Rresp].\n    Then tests by comparing the transformation of [Pstim] to [Presp]. This procedure is repeated\n    for each regularization parameter alpha in [alphas]. The correlation between each prediction and\n    each response for each alpha is returned. Note that the regression weights are NOT returned.\n\n    Parameters\n    ----------\n    Rstim : array_like, shape (TR, N)\n        Training stimuli with TR time points and N features. Each feature should be Z-scored across time.\n    Pstim : array_like, shape (TP, N)\n        Test stimuli with TP time points and N features. Each feature should be Z-scored across time.\n    Rresp : array_like, shape (TR, M)\n        Training responses with TR time points and M responses (voxels, neurons, what-have-you).\n        Each response should be Z-scored across time.\n    Presp : array_like, shape (TP, M)\n        Test responses with TP time points and M responses.\n    alphas : list or array_like, shape (A,)\n        Ridge parameters to be tested. Should probably be log-spaced. np.logspace(0, 3, 20) works well.\n    normalpha : boolean\n        Whether ridge parameters should be normalized by the Frobenius norm of Rstim. Good for\n        comparing models with different numbers of parameters.\n    dtype : np.dtype\n        All data will be cast as this dtype for computation. np.single is used by default for memory\n        efficiency.\n    corrmin : float in [0..1]\n        Purely for display purposes. After each alpha is tested, the number of responses with correlation\n        greater than corrmin minus the number of responses with correlation less than negative corrmin\n        will be printed. For long-running regressions this vague metric of non-centered skewness can\n        give you a rough sense of how well the model is working before it's done.\n    singcutoff : float\n        The first step in ridge regression is computing the singular value decomposition (SVD) of the\n        stimulus Rstim. If Rstim is not full rank, some singular values will be approximately equal\n        to zero and the corresponding singular vectors will be noise. These singular values/vectors\n        should be removed both for speed (the fewer multiplications the better!) and accuracy. Any\n        singular values less than singcutoff will be removed.\n    use_corr : boolean\n        If True, this function will use correlation as its metric of model fit. If False, this function\n        will instead use variance explained (R-squared) as its metric of model fit. For ridge regression\n        this can make a big difference -- highly regularized solutions will have very small norms and\n        will thus explain very little variance while still leading to high correlations, as correlation\n        is scale-free while R**2 is not.\n\n    Returns\n    -------\n    Rcorrs : array_like, shape (A, M)\n        The correlation between each predicted response and each column of Presp for each alpha.\n    \n    \"\"\"\n    ## Calculate SVD of stimulus matrix\n    logger.info(\"Doing SVD...\")\n    try:\n        U,S,Vh = np.linalg.svd(Rstim, full_matrices=False)\n    except np.linalg.LinAlgError as e:\n        logger.info(\"NORMAL SVD FAILED, trying more robust dgesvd..\")\n        from text.regression.svd_dgesvd import svd_dgesvd\n        U,S,Vh = svd_dgesvd(Rstim, full_matrices=False)\n\n    ## Truncate tiny singular values for speed\n    origsize = S.shape[0]\n    ngoodS = np.sum(S>singcutoff)\n    nbad = origsize-ngoodS\n    U = U[:,:ngoodS]\n    S = S[:ngoodS]\n    Vh = Vh[:ngoodS]\n    logger.info(\"Dropped %d tiny singular values.. (U is now %s)\"%(nbad, str(U.shape)))\n\n    ## Normalize alpha by the Frobenius norm\n    #frob = np.sqrt((S**2).sum()) ## Frobenius!\n    frob = S[0]\n    #frob = S.sum()\n    logger.info(\"Training stimulus has Frobenius norm: %0.03f\"%frob)\n    if normalpha:\n        nalphas = alphas * frob\n    else:\n        nalphas = alphas\n\n    ## Precompute some products for speed\n    UR = np.dot(U.T, Rresp) ## Precompute this matrix product for speed\n    PVh = np.dot(Pstim, Vh.T) ## Precompute this matrix product for speed\n    \n    #Prespnorms = np.apply_along_axis(np.linalg.norm, 0, Presp) ## Precompute test response norms\n    zPresp = zs(Presp)\n    Prespvar = Presp.var(0)\n    Rcorrs = [] ## Holds training correlations for each alpha\n    for na, a in zip(nalphas, alphas):\n        #D = np.diag(S/(S**2+a**2)) ## Reweight singular vectors by the ridge parameter \n        D = S/(S**2+na**2) ## Reweight singular vectors by the (normalized?) ridge parameter\n        \n        pred = np.dot(mult_diag(D, PVh, left=False), UR) ## Best (1.75 seconds to prediction in test)\n        # pred = np.dot(mult_diag(D, np.dot(Pstim, Vh.T), left=False), UR) ## Better (2.0 seconds to prediction in test)\n        \n        # pvhd = reduce(np.dot, [Pstim, Vh.T, D]) ## Pretty good (2.4 seconds to prediction in test)\n        # pred = np.dot(pvhd, UR)\n        \n        # wt = reduce(np.dot, [Vh.T, D, UR]).astype(dtype) ## Bad (14.2 seconds to prediction in test)\n        # wt = reduce(np.dot, [Vh.T, D, U.T, Rresp]).astype(dtype) ## Worst\n        # pred = np.dot(Pstim, wt) ## Predict test responses\n\n        if use_corr:\n            #prednorms = np.apply_along_axis(np.linalg.norm, 0, pred) ## Compute predicted test response norms\n            #Rcorr = np.array([np.corrcoef(Presp[:,ii], pred[:,ii].ravel())[0,1] for ii in range(Presp.shape[1])]) ## Slowly compute correlations\n            #Rcorr = np.array(np.sum(np.multiply(Presp, pred), 0)).squeeze()/(prednorms*Prespnorms) ## Efficiently compute correlations\n            Rcorr = (zPresp*zs(pred)).mean(0)\n        else:\n            ## Compute variance explained\n            resvar = (Presp-pred).var(0)\n            Rcorr = np.clip(1-(resvar/Prespvar), 0, 1)\n            \n        Rcorr[np.isnan(Rcorr)] = 0\n        Rcorrs.append(Rcorr)\n        \n        log_template = \"Training: alpha=%0.3f, mean corr=%0.5f, max corr=%0.5f, over-under(%0.2f)=%d\"\n        log_msg = log_template % (a,\n                                  np.mean(Rcorr),\n                                  np.max(Rcorr),\n                                  corrmin,\n                                  (Rcorr>corrmin).sum()-(-Rcorr>corrmin).sum())\n        if logger is not None:\n            logger.info(log_msg)\n        else:\n            print (log_msg)\n    \n    return Rcorrs\n\n\ndef bootstrap_ridge(Rstim, Rresp, Pstim, Presp, alphas, nboots, chunklen, nchunks, dtype=np.single,\n                    corrmin=0.2, joined=None, singcutoff=1e-10, normalpha=False, single_alpha=False,\n                    use_corr=True, logger=logging.getLogger(\"ridge_corr\")):\n    \"\"\"Uses ridge regression with a bootstrapped held-out set to get optimal alpha values for each response.\n    [nchunks] random chunks of length [chunklen] will be taken from [Rstim] and [Rresp] for each regression\n    run.  [nboots] total regression runs will be performed.  The best alpha value for each response will be\n    averaged across the bootstraps to estimate the best alpha for that response.\n    \n    If [joined] is given, it should be a list of lists where the STRFs for all the voxels in each sublist \n    will be given the same regularization parameter (the one that is the best on average).\n    \n    Parameters\n    ----------\n    Rstim : array_like, shape (TR, N)\n        Training stimuli with TR time points and N features. Each feature should be Z-scored across time.\n    Rresp : array_like, shape (TR, M)\n        Training responses with TR time points and M different responses (voxels, neurons, what-have-you).\n        Each response should be Z-scored across time.\n    Pstim : array_like, shape (TP, N)\n        Test stimuli with TP time points and N features. Each feature should be Z-scored across time.\n    Presp : array_like, shape (TP, M)\n        Test responses with TP time points and M different responses. Each response should be Z-scored across\n        time.\n    alphas : list or array_like, shape (A,)\n        Ridge parameters that will be tested. Should probably be log-spaced. np.logspace(0, 3, 20) works well.\n    nboots : int\n        The number of bootstrap samples to run. 15 to 30 works well.\n    chunklen : int\n        On each sample, the training data is broken into chunks of this length. This should be a few times \n        longer than your delay/STRF. e.g. for a STRF with 3 delays, I use chunks of length 10.\n    nchunks : int\n        The number of training chunks held out to test ridge parameters for each bootstrap sample. The product\n        of nchunks and chunklen is the total number of training samples held out for each sample, and this \n        product should be about 20 percent of the total length of the training data.\n    dtype : np.dtype\n        All data will be cast as this dtype for computation. np.single is used by default for memory efficiency,\n        as using np.double will thrash most machines on a big problem. If you want to do regression on \n        complex variables, this should be changed to np.complex128.\n    corrmin : float in [0..1]\n        Purely for display purposes. After each alpha is tested for each bootstrap sample, the number of \n        responses with correlation greater than this value will be printed. For long-running regressions this\n        can give a rough sense of how well the model works before it's done.\n    joined : None or list of array_like indices\n        If you want the STRFs for two (or more) responses to be directly comparable, you need to ensure that\n        the regularization parameter that they use is the same. To do that, supply a list of the response sets\n        that should use the same ridge parameter here. For example, if you have four responses, joined could\n        be [np.array([0,1]), np.array([2,3])], in which case responses 0 and 1 will use the same ridge parameter\n        (which will be parameter that is best on average for those two), and likewise for responses 2 and 3.\n    singcutoff : float\n        The first step in ridge regression is computing the singular value decomposition (SVD) of the\n        stimulus Rstim. If Rstim is not full rank, some singular values will be approximately equal\n        to zero and the corresponding singular vectors will be noise. These singular values/vectors\n        should be removed both for speed (the fewer multiplications the better!) and accuracy. Any\n        singular values less than singcutoff will be removed.\n    normalpha : boolean\n        Whether ridge parameters (alphas) should be normalized by the Frobenius norm of Rstim. Good for rigorously\n        comparing models with different numbers of parameters.\n    single_alpha : boolean\n        Whether to use a single alpha for all responses. Good for identification/decoding.\n    use_corr : boolean\n        If True, this function will use correlation as its metric of model fit. If False, this function\n        will instead use variance explained (R-squared) as its metric of model fit. For ridge regression\n        this can make a big difference -- highly regularized solutions will have very small norms and\n        will thus explain very little variance while still leading to high correlations, as correlation\n        is scale-free while R**2 is not.\n    \n    Returns\n    -------\n    wt : array_like, shape (N, M)\n        Regression weights for N features and M responses.\n    corrs : array_like, shape (M,)\n        Validation set correlations. Predicted responses for the validation set are obtained using the regression\n        weights: pred = np.dot(Pstim, wt), and then the correlation between each predicted response and each \n        column in Presp is found.\n    alphas : array_like, shape (M,)\n        The regularization coefficient (alpha) selected for each voxel using bootstrap cross-validation.\n    bootstrap_corrs : array_like, shape (A, M, B)\n        Correlation between predicted and actual responses on randomly held out portions of the training set,\n        for each of A alphas, M voxels, and B bootstrap samples.\n    valinds : array_like, shape (TH, B)\n        The indices of the training data that were used as \"validation\" for each bootstrap sample.\n    \"\"\"\n    nresp, nvox = Rresp.shape\n    bestalphas = np.zeros((nboots, nvox))  ## Will hold the best alphas for each voxel\n    valinds = [] ## Will hold the indices into the validation data for each bootstrap\n    \n    Rcmats = []\n    for bi in counter(range(nboots), countevery=1, total=nboots):\n        logger.info(\"Selecting held-out test set..\")\n        allinds = range(nresp)\n        indchunks = list(zip(*[iter(allinds)]*chunklen))\n        random.shuffle(indchunks)\n        heldinds = list(itools.chain(*indchunks[:nchunks]))\n        notheldinds = list(set(allinds)-set(heldinds))\n        valinds.append(heldinds)\n        \n        RRstim = Rstim[notheldinds,:]\n        PRstim = Rstim[heldinds,:]\n        RRresp = Rresp[notheldinds,:]\n        PRresp = Rresp[heldinds,:]\n        \n        ## Run ridge regression using this test set\n        Rcmat = ridge_corr(RRstim, PRstim, RRresp, PRresp, alphas,\n                           dtype=dtype, corrmin=corrmin, singcutoff=singcutoff,\n                           normalpha=normalpha, use_corr=use_corr)\n        \n        Rcmats.append(Rcmat)\n    \n    ## Find weights for each voxel\n    try:\n        U,S,Vh = np.linalg.svd(Rstim, full_matrices=False)\n    except np.linalg.LinAlgError as e:\n        logger.info(\"NORMAL SVD FAILED, trying more robust dgesvd..\")\n        from text.regression.svd_dgesvd import svd_dgesvd\n        U,S,Vh = svd_dgesvd(Rstim, full_matrices=False)\n\n    ## Normalize alpha by the Frobenius norm\n    #frob = np.sqrt((S**2).sum()) ## Frobenius!\n    frob = S[0]\n    #frob = S.sum()\n    logger.info(\"Total training stimulus has Frobenius norm: %0.03f\"%frob)\n    if normalpha:\n        nalphas = alphas * frob\n    else:\n        nalphas = alphas\n\n    allRcorrs = np.dstack(Rcmats)\n    if not single_alpha:\n        logger.info(\"Finding best alpha for each response..\")\n        if joined is None:\n            ## Find best alpha for each voxel\n            meanbootcorrs = allRcorrs.mean(2)\n            bestalphainds = np.argmax(meanbootcorrs, 0)\n            valphas = nalphas[bestalphainds]\n        else:\n            ## Find best alpha for each group of voxels\n            valphas = np.zeros((nvox,))\n            for jl in joined:\n                jcorrs = allRcorrs[:,jl,:].mean(1).mean(1) ## Mean across voxels in the set, then mean across bootstraps\n                bestalpha = np.argmax(jcorrs)\n                valphas[jl] = nalphas[bestalpha]\n    else:\n        logger.info(\"Finding single best alpha..\")\n        meanbootcorr = allRcorrs.mean(2).mean(1)\n        bestalphaind = np.argmax(meanbootcorr)\n        bestalpha = alphas[bestalphaind]\n        valphas = np.array([bestalpha]*nvox)\n        logger.info(\"Best alpha = %0.3f\"%bestalpha)\n\n    logger.info(\"Computing weights for each response using entire training set..\")\n    UR = np.dot(U.T, np.nan_to_num(Rresp))\n    pred = np.zeros(Presp.shape)\n    wt = np.zeros((Rstim.shape[1], Rresp.shape[1]))\n    for ai,alpha in enumerate(nalphas):\n        selvox = np.nonzero(valphas==alpha)[0]\n        awt = reduce(np.dot, [Vh.T, np.diag(S/(S**2+alpha**2)), UR[:,selvox]])\n        pred[:,selvox] = np.dot(Pstim, awt)\n        wt[:,selvox] = awt\n\n    ## Find test correlations\n    nnpred = np.nan_to_num(pred)\n    corrs = np.nan_to_num(np.array([np.corrcoef(Presp[:,ii], nnpred[:,ii].ravel())[0,1] for ii in range(Presp.shape[1])]))\n\n    return wt, corrs, valphas, allRcorrs, valinds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:01:02.038743Z","iopub.execute_input":"2025-07-24T01:01:02.039066Z","iopub.status.idle":"2025-07-24T01:01:02.074638Z","shell.execute_reply.started":"2025-07-24T01:01:02.039032Z","shell.execute_reply":"2025-07-24T01:01:02.073780Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# MEG Sensor plot","metadata":{}},{"cell_type":"code","source":"import os\n\nhome=os.path.expanduser(\"~\")\n\ndef topoplot(\n    mat,\n    nrow=4,\n    ncol=5,\n    time_step=25,\n    time_start=0,\n    cmap=\"RdBu_r\",\n    vmin=-0.1,\n    vmax=0.1,\n    figsize=(15, 15),\n    fontsize=16,\n):\n    \"\"\"Creates helmet plots for sensor-space MEG data (based on MNE visualization)\n\n    Args:\n        mat (2d numpy array): data to plot of size N sensors x M timepoints\n        nrow (int, optional): number of rows in plot. Defaults to 4.\n        ncol (int, optional): number of columns in plot. Defaults to 5.\n        time_step (int, optional): time window length. Defaults to 25.\n        time_start (int, optional): what time to start plotting. Defaults to 0.\n        cmap (str, optional): colormap name. Defaults to 'RdBu_r'.\n        vmin (float, optional): sets the colorbar min. Defaults to -0.1.\n        vmax (float, optional): sets the colorbar max. Defaults to 0.1.\n        figsize (tuple, optional): figure size. Defaults to (15,15).\n        fontsize (int, optional): font size. Defaults to 16.\n\n    Returns:\n        figure handle\n    \"\"\"\n\n    from sklearn.metrics.pairwise import euclidean_distances\n    import csv\n    import numpy as np\n    import mne\n    import matplotlib.pyplot as plt\n\n    # gets sensor locations\n    with open(\"../input/extra-divergence-meg-data/locations.txt\", \"r\") as f:\n        locs = csv.reader(f, delimiter=\",\")\n        loc306 = np.asarray(\n            [[float(w1[0].split(\" \")[1]), float(w1[0].split(\" \")[2])] for w1 in locs]\n        )\n    loc102 = loc306[::3]\n    loc = {306: loc306, 102: loc102}[mat.shape[0]]  # pick the correct channel locations\n\n    fig, ax = plt.subplots(nrows=nrow, ncols=ncol, figsize=figsize)\n    i = 0\n    for row in ax:\n        for col in row:\n            if i < mat.shape[1]:\n                h = mne.viz.plot_topomap(\n                    mat[:, i],\n                    loc,\n                    vlim=(vmin,vmax),\n                    axes=col,\n                    cmap=cmap,\n                    show=False,\n                    contours = 0,\n                )\n            i += 1\n    i = 0\n    for row in ax:\n        for col in row:\n            col.set_title(\n                \"{} to {} ms\".format(\n                    i * time_step + time_start, (i + 1) * time_step + time_start\n                ),\n                fontsize=fontsize,\n            )\n            i += 1\n\n    fig.subplots_adjust(right=0.8)\n    cbar_ax = fig.add_axes([1.00, 0.15, 0.01, 0.71])\n    cbar = fig.colorbar(h[0], cax=cbar_ax)\n    cbar.ax.tick_params(labelsize=fontsize)\n\n    # set the font type and size of the colorbar\n    for l in cbar.ax.yaxis.get_ticklabels():\n        l.set_size(20)\n\n    plt.tight_layout()\n    return fig\n\ndef single_topoplot(\n    mat,\n    cmap=\"RdBu_r\",\n    vmin=-0.1,\n    vmax=0.1,\n    figsize=(5,5),\n    fontsize=16,\n):\n    \"\"\"Creates single helmet plot for sensor-space MEG data (based on MNE visualization)\n\n    Args:\n        mat (2d numpy array): data to plot of size N sensors x M timepoints\n        cmap (str, optional): colormap name. Defaults to 'RdBu_r'.\n        vmin (float, optional): sets the colorbar min. Defaults to -0.1.\n        vmax (float, optional): sets the colorbar max. Defaults to 0.1.\n        figsize (tuple, optional): figure size. Defaults to (15,15).\n        fontsize (int, optional): font size. Defaults to 16.\n\n    Returns:\n        figure handle\n    \"\"\"\n\n    from sklearn.metrics.pairwise import euclidean_distances\n    import csv\n    import numpy as np\n    import mne\n    import matplotlib.pyplot as plt\n\n    # gets sensor locations\n    with open(\"../input/extra-divergence-meg-data/locations.txt\", \"r\") as f:\n        locs = csv.reader(f, delimiter=\",\")\n        loc306 = np.asarray(\n            [[float(w1[0].split(\" \")[1]), float(w1[0].split(\" \")[2])] for w1 in locs]\n        )\n    loc102 = loc306[::3]\n    loc = {306: loc306, 102: loc102}[mat.shape[0]]  # pick the correct channel locations\n\n    fig = plt.figure(figsize=figsize)\n    h = mne.viz.plot_topomap(\n                    mat,\n                    loc,\n                    vlim=(vmin,vmax),\n                    cmap=cmap,\n                    show=False,\n                    size=5,\n                )\n\n    fig.subplots_adjust(right=0.7)\n    cbar_ax = fig.add_axes([1.05, 0.15, 0.05, 0.7])\n    cbar = fig.colorbar(h[0], cax=cbar_ax)\n    cbar.ax.tick_params(labelsize=fontsize)\n\n    # set the font type and size of the colorbar\n    for l in cbar.ax.yaxis.get_ticklabels():\n        l.set_size(20)\n\n    plt.tight_layout()\n    return fig","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T02:23:36.989179Z","iopub.execute_input":"2025-07-24T02:23:36.989509Z","iopub.status.idle":"2025-07-24T02:23:37.003703Z","shell.execute_reply.started":"2025-07-24T02:23:36.989486Z","shell.execute_reply":"2025-07-24T02:23:37.002785Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Generate LM Embedding for HP","metadata":{}},{"cell_type":"code","source":"# Generate LM Embedding for HP\nimport os\nimport sys\nimport numpy as np\nimport string\nimport pickle\nimport argparse\n\nimport matplotlib.pyplot as plt\n\nfrom scipy.stats import pearsonr\nfrom scipy.stats import chi2\nfrom scipy.stats import zscore\nimport scipy.io as sio\nfrom scipy.io import loadmat\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\n\nimport statsmodels.api as sm\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\n# from mat4py import loadmat\n\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader, random_split\n\nsys.path.append(\"../\")\n# from dataloader.dataloader import HP_dataset_denoised\n\n# from utils import utils\n# from utils.ridge.ridge import bootstrap_ridge\n\nnp.set_printoptions(precision=3,suppress=True)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n\nhome=os.path.expanduser(\"~\")\n\nparser = argparse.ArgumentParser()\n\nparser.add_argument(\"--dataset\", default=\"HP\")\nparser.add_argument(\"--base_data_path\", default=\"../input/divergence-meg-data/\")\nparser.add_argument(\"--chapter\", type=int, default=1)\nparser.add_argument(\"--meg_offset\", type=int, default=0)\n\nparser.add_argument(\"--batch_size\", type=int, default=4)\nparser.add_argument(\"--sequence_length\", type=int, default=20)\nparser.add_argument(\"--lm_name\", default=\"GPT2-xl\")\nparser.add_argument(\"--model_info\", default=\"base\")\nparser.add_argument(\"--lm_path\",default = \"../working/interim_data/lm_embeddings/\")\n###################################################################################\nargs_list = [\n    \"--dataset\", \"HP\",\n    \"--base_data_path\", \"../input/divergence-meg-data/\",\n    \"--chapter\", \"1\",\n    \"--meg_offset\", \"0\",\n    \"--batch_size\", \"4\",\n    \"--sequence_length\", \"20\",\n    \"--lm_name\", \"GPT2-xl\",\n    \"--model_info\", \"base\",\n    \"--lm_path\",\"../working/interim_data/lm_embeddings/\" # Provide a value for lm_path as it has no default\n]\n\n# --- Example of using the args_list ---\nprint(\"--- Parsing with provided args_list ---\")\nargs = parser.parse_args(args_list)\n###################################################################################\nargs.no_cuda=not torch.cuda.is_available()\n\nprint(\"Echo arguments:\",args)\n\n## Load datasetGPT2\nwhole_data = HP_dataset_denoised(args)\nprint(\"Number of words:\", len(whole_data))\n\n## Load LM\nif args.model_info==\"base\":\t# if loading base model\n    tokenizer,model=load_tokenizer_and_model_from_transformers(args.lm_name)\nelse:\t# if loading finetuned model\n    if args.lm_name == \"Llama-2\":\n        tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\", truncation_side=\"left\", padding_side=\"left\")\n    elif args.lm_name == \"GPT2-xl\":\n        tokenizer = AutoTokenizer.from_pretrained(\"gpt2-xl\", truncation_side=\"left\", padding_side=\"left\")\n    else:\n        raise ValueError(\"Not a valid lm_name.\")\n    model = AutoModelForCausalLM.from_pretrained(args.lm_path, output_hidden_states=True)\n    \ntokenizer.pad_token = tokenizer.bos_token\n\nif not args.no_cuda:\n    model=model.to(\"cuda:0\")\nmodel.eval();\n\n\n# #################################################--- Begin of new code: narrative categorization setup ---#################################################\nfrom nltk.sentiment import SentimentIntensityAnalyzer\nimport nltk\nnltk.download('vader_lexicon')\n\nsia = SentimentIntensityAnalyzer()\n\n# Define keyword sets for rough rule-based tagging\ndialogue_markers = {'said', 'asked', 'replied', 'shouted'}\nemotion_words = {'angry', 'sad', 'happy', 'nervous', 'afraid', 'proud', 'furious', 'pleased'}\naction_words = {'walked', 'ran', 'drove', 'left', 'turned', 'put', 'looked', 'came'}\nmagic_words = {'wand', 'cloak', 'owl', 'spell', 'wizard', 'witch', 'magic'}\ndescription_words = {'Privet', 'Drive', 'long', 'thin', 'square', 'dark', 'sky', 'street'}\n\ndef categorize_word(word):\n    w = word.lower().strip(string.punctuation)\n    if w in dialogue_markers:\n        return \"dialogue\"\n    elif w in emotion_words or sia.polarity_scores(w)[\"compound\"] != 0:\n        return \"emotional\"\n    elif w in action_words:\n        return \"action\"\n    elif w in magic_words:\n        return \"magic\"\n    elif w in description_words:\n        return \"description\"\n    else:\n        return \"other\"\n# #################################################----- End of new code ---#################################################\n\n\n\n\n## Get LM embeddings\ndataloader=DataLoader(whole_data, batch_size=args.batch_size)\n\nall_logits=list()\nall_embeddings=list()\nall_last_words=list()\nall_megs=list()\nword_categories = []\nfor batch_i,(batch_text_idx,batch_meg) in enumerate(dataloader):\n    batch_text=list()\n    batch_last_words=list()\n    for text_idx in batch_text_idx:\n        line=list()\n        for word_idx in text_idx:\n            word=whole_data.index_to_word[int(word_idx)]\n            line.append(word)\n            last_word=word.strip(string.punctuation) # remove punctuations at start and end of the word\n        line=\" \".join(line)\n        # line+=tokenizer.bos_token\n        batch_text.append(line)\n        batch_last_words.append(last_word)\n# #################################################--- Begin of new code: categorize word ---#################################################\n        category = categorize_word(last_word)\n        word_categories.append(category)\n# #################################################--- End of new code ---#################################################\n\n    encodings = tokenizer(batch_text, return_tensors=\"pt\", padding=True)['input_ids']\n    # encodings = tokenizer(batch_text, return_tensors=\"pt\"args_list, truncation=True, max_length=args.sequence_length)['input_ids']\n    if not args.no_cuda:\n        encodings=encodings.to(\"cuda:0\")\n\n    batch_last_word_pos=find_indices_of_last_word_in_batch(tokenizer,batch_last_words,encodings)\n\n    with torch.no_grad():\n        output=model(encodings)\n\n        for i,sentence_logits in enumerate(output['logits']):\n            word_start,word_end=batch_last_word_pos[i]\n            all_logits.append(sentence_logits[word_start-1:word_end].detach().cpu().numpy())\n            embeddings=np.vstack([torch.mean(embed[i,word_start:word_end+1],dim=0).detach().cpu().numpy()  for embed in output['hidden_states']])\n            all_embeddings.append(embeddings)\n            all_last_words.append(encodings[i][word_start:word_end+1].detach().cpu().numpy())\n        all_megs.append(batch_meg.detach().cpu().numpy())\n\n    if batch_i%100==0:\n        print(f\"Batch {batch_i+1}/{len(dataloader)}...\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:01:02.119935Z","iopub.execute_input":"2025-07-24T01:01:02.120259Z","iopub.status.idle":"2025-07-24T01:04:46.752135Z","shell.execute_reply.started":"2025-07-24T01:01:02.120232Z","shell.execute_reply":"2025-07-24T01:04:46.749071Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nall_megs=np.vstack(all_megs)\t# (word, meg_channel)\nall_embeddings=np.stack(all_embeddings,axis=1)\t# (layer, word, embedding_dim)\n\ndumped_data=dict(\n        all_megs=all_megs,\n        all_embeddings=all_embeddings,\n        all_last_words=all_last_words,\n        all_logits=all_logits\n    )\n\n\n\nos.makedirs(\"../working/interim_data/lm_embeddings/\",exist_ok=True)\npickle.dump(dumped_data,\n    open(f\"../working/interim_data/lm_embeddings/{args.dataset}_chpt{args.chapter}_{args.lm_name}_{args.model_info}.pkl\",\"wb\"))\n# #################################################--- Begin of new code: save word categories ---#################################################\npickle.dump(word_categories, open(\"../working/interim_data/lm_embeddings/hp1_word_categories.pkl\", \"wb\"))\n# #################################################--- End of new code ---#################################################","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:24:37.360539Z","iopub.execute_input":"2025-07-24T01:24:37.361163Z","iopub.status.idle":"2025-07-24T01:24:45.134552Z","shell.execute_reply.started":"2025-07-24T01:24:37.361137Z","shell.execute_reply":"2025-07-24T01:24:45.133623Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(word_categories)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:04:46.752682Z","iopub.status.idle":"2025-07-24T01:04:46.752962Z","shell.execute_reply.started":"2025-07-24T01:04:46.752835Z","shell.execute_reply":"2025-07-24T01:04:46.752848Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Categories","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:04:46.753778Z","iopub.status.idle":"2025-07-24T01:04:46.754045Z","shell.execute_reply.started":"2025-07-24T01:04:46.753925Z","shell.execute_reply":"2025-07-24T01:04:46.753936Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# os.makedirs(\"../working/interim_data/lm_embeddings/\",exist_ok=True)\n# pickle.dump(dumped_data,\n#     open(f\"../working/interim_data/lm_embeddings/{args.dataset}_chpt{args.chapter}_{args.lm_name}_{args.model_info}.pkl\",\"wb\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:04:46.755394Z","iopub.status.idle":"2025-07-24T01:04:46.755704Z","shell.execute_reply.started":"2025-07-24T01:04:46.755522Z","shell.execute_reply":"2025-07-24T01:04:46.755532Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.listdir(\"../working/interim_data/lm_embeddings/\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:04:46.757070Z","iopub.status.idle":"2025-07-24T01:04:46.757431Z","shell.execute_reply.started":"2025-07-24T01:04:46.757244Z","shell.execute_reply":"2025-07-24T01:04:46.757261Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# os.makedirs(\"../working/interim_data/lm_embeddings/\",exist_ok=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:04:46.758973Z","iopub.status.idle":"2025-07-24T01:04:46.759286Z","shell.execute_reply.started":"2025-07-24T01:04:46.759105Z","shell.execute_reply":"2025-07-24T01:04:46.759120Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Generate data for analysis HP","metadata":{}},{"cell_type":"code","source":"#Generate data for analysis HP\nimport os\nimport sys\nimport numpy as np\nimport string\nimport pickle\nimport argparse\n\nimport matplotlib.pyplot as plt\n\nfrom scipy.stats import pearsonr\nfrom scipy.stats import chi2\nfrom scipy.stats import zscore\nimport scipy.io as sio\nfrom scipy.io import loadmat\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\n\nimport statsmodels.api as sm\n\n# from mat4py import loadmat\n\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader, random_split\n\nsys.path.append(\"../\")\n# from dataloader.dataloader import HP_dataset_denoised\n# from utils import meg_sensor_plot\n# from utils import utils\n# from utils.ridge.ridge import bootstrap_ridge\n\nnp.set_printoptions(precision=3,suppress=True)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n\nhome=os.path.expanduser(\"~\")\n\nparser = argparse.ArgumentParser()\n\nparser.add_argument(\"--dataset\", default=\"HP\")\nparser.add_argument(\"--base_data_path\", default=\"../input/divergence-meg-data/\")\nparser.add_argument(\"--chapter\", type=int, default=1)\nparser.add_argument(\"--meg_offset\", type=int, default=0)\nparser.add_argument(\"--p_thresh\", type=float, default=0.001)\n\nparser.add_argument(\"--sequence_length\", type=int, default=20)\nparser.add_argument(\"--lm_name\", default=\"GPT2-xl\")\nparser.add_argument(\"--model_info\", default=\"base\")\nparser.add_argument(\"--layer\", type=int, default=-1)\n\n\n# --- FIX STARTS HERE ---\n# Simulate command-line arguments by passing a list of strings\n\n# Manually construct the list based on the defaults you want to use\nargs_list = [\n    \"--dataset\", \"HP\",\n    \"--base_data_path\", \"../input/divergence-meg-data/\", # Use the path variable\n    \"--chapter\", \"1\",\n    \"--meg_offset\", \"0\",\n    \"--p_thresh\", \"0.001\", # Convert float to string\n\n    \"--sequence_length\", \"20\",\n    \"--lm_name\", \"GPT2-xl\",\n    \"--model_info\", \"base\",\n    \"--layer\", \"-1\"\n]\n\n# Pass the list of arguments to parse_args()\nargs = parser.parse_args(args_list) # <--- The fix is here\n# --- FIX ENDS HERE ---\n\n\nargs.lm_embed_path = f\"../working/interim_data/lm_embeddings/{args.dataset}_chpt{args.chapter}_{args.lm_name}_{args.model_info}.pkl\"\n\nprint(\"Echo arguments:\",args)\n\n## Load MEG data\nwhole_data = HP_dataset_denoised(args)\nmeg_data=whole_data.all_megs[args.sequence_length:]\t# (word, meg_channel, time)\n\n## Load LM embeddings\ndata=pickle.load(open(args.lm_embed_path,\"rb\"))\nall_embeddings=data[\"all_embeddings\"]\t# (layer, word, embedding_dim)\n\nword_num = meg_data.shape[0]\nchannel_num = meg_data.shape[1]\ntimepoint_num = meg_data.shape[2]\nlayer_num = 1\n\n## init arrays\nall_corrs = np.zeros((layer_num, timepoint_num, channel_num))\nall_sig_channels = np.zeros((layer_num, timepoint_num, channel_num), dtype=int)\nall_pred = np.zeros((layer_num, timepoint_num, word_num, channel_num))\nall_MSE = np.zeros((layer_num, timepoint_num, word_num))\nall_cos_sim = np.zeros((layer_num, timepoint_num, word_num))\n\n#%% ##########################################----NEW----BEGINS----#######################################################\nnarrative_categories = np.array(word_categories)\ncategories = np.unique(narrative_categories)\nMSEs_for_channels = np.zeros((timepoint_num, channel_num))*np.nan  # shape: (timepoints, channels)\ncosine_sim_channels = np.zeros((timepoint_num, channel_num))*np.nan  # shape: (timepoints, channels)\nmse_by_category = {tt: {cat: [] for cat in categories} for tt in range(timepoint_num)}\ncos_by_category = {tt: {cat: [] for cat in categories} for tt in range(timepoint_num)}\ncategory_word_indices = {cat: np.where(narrative_categories == cat)[0] for cat in categories}\ndivergence_by_category = {cat: np.zeros((timepoint_num, channel_num)) for cat in categories}\n\n#%% ##########################################----NEW----ENDS----#######################################################\n## Ridge regression\n## Variable \"tt\" was \"time\" in the original code and was changed due to conflict with time module (time.time())\nprint(\"Ridge regression...\")\nfor tt in range(timepoint_num):\n    brain_responses = meg_data[:,:,tt]\n    embeddings = all_embeddings[args.layer]\n    brain_responses_pred = do_ridge_regression(embeddings, brain_responses)\n\n    all_pred[0, tt] = brain_responses_pred\n\n    for ch, (pred,actual) in enumerate(zip(brain_responses_pred.T, brain_responses.T)):\t# for each channel, all words\n        corr, pvalue = pearsonr(pred,actual,alternative=\"greater\")\n        all_corrs[0, tt, ch] = corr\n        if pvalue < args.p_thresh:\n            all_sig_channels[0, tt, ch] = 1\n\n    sig_channels = all_sig_channels[0, tt]\n    print(f\"layer {args.layer}, {tt*25}-{(tt+1)*25}ms: {np.sum(sig_channels)}\")\n\n    for word, (pred,actual) in enumerate(zip(brain_responses_pred, brain_responses)):\t# for each word, all sig channels\n        all_MSE[0, tt, word] = np.linalg.norm(pred[sig_channels]-actual[sig_channels], ord=2) ** 2 / len(sig_channels)\n        all_cos_sim[0, tt, word] = cosine_similarity(pred[sig_channels],actual[sig_channels])\n\n\n        mse = np.linalg.norm(pred[sig_channels] - actual[sig_channels], ord=2) ** 2 / len(sig_channels)\n        cos = cosine_similarity(pred[sig_channels], actual[sig_channels])\n#%% ##########################################----NEW----BEGINS----#######################################################\n        category = narrative_categories[word]  # 'dialogue', 'action', or 'emotion'\n\n        if category not in categories:\n            continue  # skip unknowns\n        # ========== GROUP BY CATEGORY ==========\n        mse_by_category[tt][category].append(mse)\n        cos_by_category[tt][category].append(cos)\n\n        for ch in range(channel_num):\n            word_idxs = category_word_indices[category]\n            preds = brain_responses_pred[word_idxs, ch]\n            actuals = brain_responses[word_idxs, ch]\n            mse = np.mean((preds[sig_channels] - actuals[sig_channels]) ** 2)/ len(sig_channels)\n\n            divergence_by_category[category][tt, ch] = mse\n\n\n\n    for ch in range(channel_num):\n        preds = brain_responses_pred[:, ch]    # shape: (words,) - predictions for one channel across all words\n        actuals = brain_responses[:, ch]       # shape: (words,) - actuals for one channel across all words\n        MSEs_for_channels[tt, ch] = np.linalg.norm(preds[sig_channels]-actuals[sig_channels], ord=2) ** 2 / len(sig_channels)\n        cosine_sim_channels[tt, ch] = cosine_similarity(preds[sig_channels],actuals[sig_channels])\n        # divergence_by_category[cat][tt, ch] = mse\n\n\n\n        # # MSE for this specific channel across all words\n        # mse = np.mean((preds[sig_channels] - actuals[sig_channels]) ** 2) / len(sig_channels)\n        # MSEs_for_channels[tt, ch] = mse\n\n        # # Cosine Similarity for this specific channel across all words\n        # # Check if norms are non-zero to avoid division by zero in cosine_similarity if any array is all zeros\n        # if np.linalg.norm(preds) > 0 and np.linalg.norm(actuals) > 0:\n        #     # Reshape to (1, -1) for sklearn.metrics.pairwise.cosine_similarity\n        #     cos_sim = cosine_similarity(preds[sig_channels], actuals[sig_channels])\n        # else:\n        #     cos_sim = np.nan # Define behavior for all-zero vectors\n\n        # cosine_sim_channels[tt, ch] = cos_sim\n\n#%% ##########################################----NEW----ENDS----#######################################################","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:40:05.927405Z","iopub.execute_input":"2025-07-24T01:40:05.927814Z","iopub.status.idle":"2025-07-24T02:10:23.774870Z","shell.execute_reply.started":"2025-07-24T01:40:05.927789Z","shell.execute_reply":"2025-07-24T02:10:23.774113Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Compare Mean Divergence Over Time","metadata":{}},{"cell_type":"code","source":"for cat in categories:\n    mean_mse = divergence_by_category[cat].mean(axis=1)\n    plt.plot(np.arange(timepoint_num)*25,mean_mse, label=cat)\n\nplt.xlabel(\"Time (ms)\")\nplt.ylabel(\"Mean MSE\")\nplt.legend()\nplt.title(\"Divergence by Narrative Type Over Time\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T02:14:06.076347Z","iopub.execute_input":"2025-07-24T02:14:06.077047Z","iopub.status.idle":"2025-07-24T02:14:06.355137Z","shell.execute_reply.started":"2025-07-24T02:14:06.077021Z","shell.execute_reply":"2025-07-24T02:14:06.354493Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Topomap Per Narrative Type","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n# Load MEG metadata\nmeg_channels = pd.read_csv('../input/extra-divergence-meg-data/MEG_Channel_Brain_Areas.csv')\nchannel_names = meg_channels['Sensor_Label'].tolist()\nchannel_regions = {\n    name: meg_channels.loc[i, 'Brain_Region']\n    for i, name in enumerate(channel_names)\n}\nmeg_channels['Sensor_Label'].tolist()\nchannel_names_mne  = [f'MEG {i:04d}' for i in channel_names]\nchannel_names_mne[:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T02:17:37.211674Z","iopub.execute_input":"2025-07-24T02:17:37.211969Z","iopub.status.idle":"2025-07-24T02:17:37.238784Z","shell.execute_reply.started":"2025-07-24T02:17:37.211948Z","shell.execute_reply":"2025-07-24T02:17:37.237543Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"info = mne.create_info(ch_names=channel_names_mne,\n                       sfreq=1000, # Assuming sfreq remains 1000\n                       ch_types=['mag'] * 102 + ['grad'] * 204) # Assuming 102 mag, 204 grad\n\nfor cat in categories:\n    mean_topo = divergence_by_category[cat].mean(axis=0)\n    single_topoplot(mean_topo,vmin = np.min(mean_topo),vmax=np.max(mean_topo))\n    plt.title(f\"{cat}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T02:24:11.423610Z","iopub.execute_input":"2025-07-24T02:24:11.424201Z","iopub.status.idle":"2025-07-24T02:24:13.704425Z","shell.execute_reply.started":"2025-07-24T02:24:11.424176Z","shell.execute_reply":"2025-07-24T02:24:13.703635Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# top-divergent channels","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Average across time (assuming MSEs_for_channels and cosine_sim_channels are shape [time, 306])\nmean_MSE_per_channel = np.mean(MSEs_for_channels, axis=0)         # shape: (306,)\nmean_cos_per_channel = np.mean(cosine_sim_channels, axis=0)       # shape: (306,)\n\n# Get top N most divergent channels (highest MSE)\ntop_n = 10\ntop_MSE_channels = np.argsort(mean_MSE_per_channel)[-top_n:][::-1]  # descending order\ntop_MSE = mean_MSE_per_channel[top_MSE_channels]\ntop_cos_for_top_MSE = mean_cos_per_channel[top_MSE_channels]       # match cosine to same channels\n\n# Load MEG metadata\nmeg_channels = pd.read_csv('../input/extra-divergence-meg-data/MEG_Channel_Brain_Areas.csv')\nchannel_names = meg_channels['Sensor_Label'].tolist()\nchannel_regions = {\n    name: meg_channels.loc[i, 'Brain_Region']\n    for i, name in enumerate(channel_names)\n}\n\n# Print info\nprint(\"\\nTop channels by HIGHEST MSE:\")\nfor idx, ch_idx in enumerate(top_MSE_channels):\n    name = channel_names[ch_idx]\n    region = channel_regions[name]\n    print(f\"{name} - Region: {region}, MSE = {top_MSE[idx]:.4f}, Cos = {top_cos_for_top_MSE[idx]:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T02:25:06.432049Z","iopub.execute_input":"2025-07-24T02:25:06.432386Z","iopub.status.idle":"2025-07-24T02:25:06.451856Z","shell.execute_reply.started":"2025-07-24T02:25:06.432363Z","shell.execute_reply":"2025-07-24T02:25:06.451040Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"single_topoplot(mean_MSE_per_channel,    vmin=np.min(mean_MSE_per_channel),\n    vmax=np.max(mean_MSE_per_channel),)\nplt.title(\"Top channels by HIGHEST MSE\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T02:25:33.719114Z","iopub.execute_input":"2025-07-24T02:25:33.720496Z","iopub.status.idle":"2025-07-24T02:25:34.144723Z","shell.execute_reply.started":"2025-07-24T02:25:33.720465Z","shell.execute_reply":"2025-07-24T02:25:34.143758Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lowest_cos_channels = np.argsort(mean_cos_per_channel)[:top_n]\nlowest_cos = mean_cos_per_channel[lowest_cos_channels]\nmse_for_lowest_cos = mean_MSE_per_channel[lowest_cos_channels]\n\nprint(\"\\nTop channels by LOWEST Cosine Similarity:\")\nfor idx, ch_idx in enumerate(lowest_cos_channels):\n    name = channel_names[ch_idx]\n    region = channel_regions[name]\n    print(f\"{name} - Region: {region}, Cos = {lowest_cos[idx]:.4f}, MSE = {mse_for_lowest_cos[idx]:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T02:25:42.657320Z","iopub.execute_input":"2025-07-24T02:25:42.657654Z","iopub.status.idle":"2025-07-24T02:25:42.663596Z","shell.execute_reply.started":"2025-07-24T02:25:42.657625Z","shell.execute_reply":"2025-07-24T02:25:42.662738Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**In This context (MEG + LM prediction):\nWe're comparing predicted brain responses and actual brain responses channel-wise.**\n\n- A negative cosine similarity in a channel suggests that:\n\n- The pattern of activation predicted by the language model is inversely correlated with the actual brain signal in that channel.\n\n\n**Interpretation:**\n\n-  This might mean the model misunderstood the representation for that word/region/timepoint.\n\n- Or the brain region may be involved in processing that is orthogonal or opposing to the language models latent representation  possibly reflecting other cognitive processes like:\n\n    - Emotion vs. logic\n\n    - Sensory vs. semantic\n\n    - Inhibition, conflict, etc.\n \n  ","metadata":{}},{"cell_type":"markdown","source":"## Furthur analysis","metadata":{}},{"cell_type":"code","source":"# For each word and category, accumulate channel-wise divergence\nmse_per_channel_by_category = {cat: np.zeros(channel_num) for cat in categories}\ncounts = {cat: 0 for cat in categories}\n\nfor tt in range(timepoint_num):\n    sig_channels = all_sig_channels[0, tt]\n\n    for word, (pred, actual) in enumerate(zip(all_pred[0, tt], meg_data[:, :, tt])):\n        category = narrative_categories[word]\n        if category not in categories:\n            continue\n\n        mse_ch = (pred - actual) ** 2  # shape: (306,)\n        mse_per_channel_by_category[category] += mse_ch\n        counts[category] += 1\n\n# Normalize\nfor cat in categories:\n    mse_per_channel_by_category[cat] /= counts[cat]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T02:28:05.254855Z","iopub.execute_input":"2025-07-24T02:28:05.255410Z","iopub.status.idle":"2025-07-24T02:28:06.178820Z","shell.execute_reply.started":"2025-07-24T02:28:05.255380Z","shell.execute_reply":"2025-07-24T02:28:06.177665Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"meg_channels['Sensor_Label'].tolist()\nchannel_names_mne  = [f'MEG {i:04d}' for i in channel_names]\nchannel_names_mne[:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:04:46.769301Z","iopub.status.idle":"2025-07-24T01:04:46.769542Z","shell.execute_reply.started":"2025-07-24T01:04:46.769432Z","shell.execute_reply":"2025-07-24T01:04:46.769442Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mean_MSE_per_channel.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:04:46.770989Z","iopub.status.idle":"2025-07-24T01:04:46.771262Z","shell.execute_reply.started":"2025-07-24T01:04:46.771152Z","shell.execute_reply":"2025-07-24T01:04:46.771163Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mean_MSE_per_channel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:04:46.771955Z","iopub.status.idle":"2025-07-24T01:04:46.772204Z","shell.execute_reply.started":"2025-07-24T01:04:46.772080Z","shell.execute_reply":"2025-07-24T01:04:46.772090Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(MSEs_for_channels.shape)\nprint(cosine_sim_channels.shape)\nprint(brain_responses.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T02:28:13.872756Z","iopub.execute_input":"2025-07-24T02:28:13.873052Z","iopub.status.idle":"2025-07-24T02:28:13.877904Z","shell.execute_reply.started":"2025-07-24T02:28:13.873032Z","shell.execute_reply":"2025-07-24T02:28:13.876920Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.mean((pred[sig_channels]-actual[sig_channels]) ** 2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:04:46.776058Z","iopub.status.idle":"2025-07-24T01:04:46.776387Z","shell.execute_reply.started":"2025-07-24T01:04:46.776217Z","shell.execute_reply":"2025-07-24T01:04:46.776234Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.linalg.norm(pred[sig_channels]-actual[sig_channels], ord=2) ** 2 / len(sig_channels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:04:46.777529Z","iopub.status.idle":"2025-07-24T01:04:46.777826Z","shell.execute_reply.started":"2025-07-24T01:04:46.777706Z","shell.execute_reply":"2025-07-24T01:04:46.777719Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":" for ch in range(channel_num):\n    plt.plot(MSEs_for_channels[:,ch])\nplt.xlabel(\"Timepoints\")\nplt.ylabel(\"MSE\")\nplt.legend()\nplt.title(\"Divergence (MSE) per Narrative Category\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T02:28:25.405033Z","iopub.execute_input":"2025-07-24T02:28:25.405362Z","iopub.status.idle":"2025-07-24T02:28:25.932678Z","shell.execute_reply.started":"2025-07-24T02:28:25.405339Z","shell.execute_reply":"2025-07-24T02:28:25.931794Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"time_points = np.arange(timepoint_num) * 25  # in ms (e.g., 0, 25, ..., 975)\n\n# Plot MSE\nplt.figure(figsize=(12, 5))\nfor cat in categories:\n    mean_mse = [np.mean(mse_by_category[tt][cat]) for tt in range(timepoint_num)]\n    plt.plot(time_points, mean_mse, label=f\"MSE - {cat}\")\nplt.xlabel(\"Time after word onset (ms)\")\nplt.ylabel(\"Mean Squared Error\")\nplt.title(\"Divergence (MSE) over Time by Narrative Category\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n# Plot Cosine Similarity\nplt.figure(figsize=(12, 5))\nfor cat in categories:\n    mean_cos = [np.mean(cos_by_category[tt][cat]) for tt in range(timepoint_num)]\n    plt.plot(time_points, mean_cos, label=f\"Cosine Sim - {cat}\")\nplt.xlabel(\"Time after word onset (ms)\")\nplt.ylabel(\"Cosine Similarity\")\nplt.title(\"Cosine Similarity over Time by Narrative Category\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T02:28:30.237858Z","iopub.execute_input":"2025-07-24T02:28:30.238189Z","iopub.status.idle":"2025-07-24T02:28:30.793767Z","shell.execute_reply.started":"2025-07-24T02:28:30.238166Z","shell.execute_reply":"2025-07-24T02:28:30.792898Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.makedirs('../working/data_for_analysis',exist_ok = True)\npickle.dump(\n    dict(\n    embedding=all_embeddings,\n    text=whole_data.all_texts,\n    actual=meg_data,\n    pred=all_pred,\n    corr=all_corrs,\n    MSE=all_MSE,\n    cos=all_cos_sim,\n    sig_channels=all_sig_channels,\n    ),\n    open(f\"../working/data_for_analysis/{args.dataset}_chpt{args.chapter}_{args.lm_name}_{args.model_info}_layer{args.layer}.pkl\",\"wb\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:04:46.781445Z","iopub.status.idle":"2025-07-24T01:04:46.781779Z","shell.execute_reply.started":"2025-07-24T01:04:46.781605Z","shell.execute_reply":"2025-07-24T01:04:46.781619Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Format Sentence","metadata":{}},{"cell_type":"code","source":"\nimport os\nimport sys\nimport numpy as np\nimport string\nimport pickle\nimport argparse\n\nimport matplotlib.pyplot as plt\n\nfrom scipy.stats import pearsonr\nfrom scipy.stats import chi2\nfrom scipy.stats import zscore\nimport scipy.io as sio\nfrom scipy.io import loadmat\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\n\nimport statsmodels.api as sm\n\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader, random_split\n\nsys.path.append(\"../\")\n# from dataloader.dataloader import HP_dataset_denoised\n# from utils import meg_sensor_plot\n# from utils import utils\n# from utils.ridge.ridge import bootstrap_ridge\n\nnp.set_printoptions(precision=3,suppress=True)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ndef save_sents(divergent_sents, similar_sents, fname):\n\n\tdata_dict = {\n\t\t\"dataset_description\": \"two chapters from 'Harry Potter and the Sorcerer's Stone'\",\n\t\t\"generation\": \"the difference between language model and human responses to these sentences\",\t    \n\t\t\"target\": \"which sentences induce different responses for language models and human responses\",\n\t\t\"user\": \"a literary analyst investigating the characteristics of words\",\n\t\t\"A_desc\": \"sentences where language models and humans show divergent responses\",\n\t\t\"B_desc\": \"sentences where language models and humans show similar responses\",\n\t\t\"example_hypotheses\": [],\n\t\t\"split\": {\n\t\t\t\"research\": {\"A_samples\": [], \"B_samples\": []},\n\t\t\t\"validation\": {\"A_samples\": [], \"B_samples\": []}\n\t\t}\n\t}\n\n\t# train/val split (no test)\n\ttrain_split_surp = int(len(divergent_sents) * 0.8)\n\ttrain_split_unsurp = int(len(similar_sents) * 0.8)\n\tdivergent_sents_train = divergent_sents[:train_split_surp]\n\tsimilar_sents_train = similar_sents[:train_split_unsurp]\n\tdivergent_sents_val = divergent_sents[train_split_surp:]\n\tsimilar_sents_val = similar_sents[train_split_unsurp:]\n\n\tdata_dict[\"split\"][\"research\"][\"A_samples\"] = divergent_sents_train\n\tdata_dict[\"split\"][\"validation\"][\"A_samples\"] = similar_sents_train\n\tdata_dict[\"split\"][\"research\"][\"B_samples\"] = divergent_sents_val\n\tdata_dict[\"split\"][\"validation\"][\"B_samples\"] = similar_sents_val\n\n\twith open(fname, \"wb\") as f:\n\t\tpickle.dump(data_dict, f)\n\t\n\t\ndef rank_sentences(words, mses, search_strings = [\".\", \"!\", \"?\"]):\n\tall_sentences = list()\n\tthis_sentence = list()\n\tmse_all_sentences = list()\n\tmse_count = 0\n\t\n\tfor i, word in enumerate(words):\n\t\tthis_sentence.append(word)\n\t\tmse_count += mses[i]\n\t\tif any(string in word for string in search_strings) and len(this_sentence) > 3: # end of a sentence\n\t\t\tall_sentences.append(\" \".join(this_sentence))\n\t\t\tmse_all_sentences.append(mse_count/len(this_sentence))\n\t\t\tthis_sentence = list()\n\t\t\tmse_count = 0\n\t\t\t\n\tsort_idx = np.argsort(mse_all_sentences)\n\treturn [all_sentences[idx] for idx in sort_idx]\n\n\n\nhome=os.path.expanduser(\"~\")\n\nparser = argparse.ArgumentParser()\n\nparser.add_argument(\"--dataset\", default=\"HP\")\nparser.add_argument(\"--sequence_length\", type=int, default=20)\n\nparser.add_argument(\"--chapter\", type=int, default=1)\n\nparser.add_argument(\"--layer\", type=int, default=-1)\n\nparser.add_argument(\"--save_path\", default=\"../working/interim_data/divergent_sents/\")\n\nparser.add_argument(\"--lm_name\", default= \"GPT2-xl\")\n\nparser.add_argument(\"--n_sents\", type=int, default=100)\n\nargs_list = [\n    \"--dataset\", \"HP\",\n    \"--sequence_length\", \"20\",\n    \"--chapter\", \"1\",\n    \"--layer\", \"-1\",\n    \"--save_path\", \"../working/interim_data/divergent_sents/\", # Use the constructed path variable\n    \"--lm_name\", \"GPT2-xl\",\n    \"--n_sents\", \"100\"\n]\n\n# --- Example of using the args_list ---\nprint(\"--- Parsing with default args_list ---\")\nargs = parser.parse_args(args_list)\n\n\nprint(\"Echo arguments:\",args)\n\nif not os.path.exists(f\"{args.save_path}formatted_sents_{args.lm_name}_layer{args.layer}_chpt{args.chapter}.pkl\"):\n    os.makedirs('../working/interim_data/divergent_sents/',exist_ok=True)\n    \n    ## Load data\n    if args.chapter==12:\n        # data1=pickle.load(open(f\"../working/interim_data/lm_embeddings/HP_chpt1_{args.lm_name}_base.pkl\",\"rb\"))\n        data1=pickle.load(open(f\"../working/data_for_analysis/HP_chpt1_{args.lm_name}_base_layer-1.pkl\",\"rb\"))\n        words1=data1['text'][args.sequence_length:]\n        MSEs1=np.mean(data1['MSE'][args.layer][12:17],axis=0)\n        # data2=pickle.load(open(f\"../working/interim_data/lm_embeddings/HP_chpt2_{args.lm_name}_base.pkl\",\"rb\"))\n        data2=pickle.load(open(f\"../working/data_for_analysis/HP_chpt2_{args.lm_name}_base_layer-1.pkl\",\"rb\"))\n        words2=data2['text'][args.sequence_length:]\n        MSEs2=np.mean(data2['MSE'][args.layer][12:17],axis=0)\n        words=words1+words2\n        MSEs=np.concatenate([MSEs1,MSEs2])\n    elif args.chapter==1:\n        # data=pickle.load(open(f\"../working/interim_data/lm_embeddings/HP_chpt1_{args.lm_name}_base.pkl\",\"rb\"))\n        data=pickle.load(open(f\"../working/data_for_analysis/HP_chpt1_{args.lm_name}_base_layer-1.pkl\",\"rb\"))\n        words=data['text'][args.sequence_length:]\n        MSEs=np.mean(data['MSE'][args.layer][12:17],axis=0)\n    elif args.chapter==2:\n        # data=pickle.load(open(f\"../working/interim_data/lm_embeddings/HP_chpt2_{args.lm_name}_base.pkl\",\"rb\"))\n        data=pickle.load(open(f\"../working/data_for_analysis/HP_chpt2_{args.lm_name}_base_layer-1.pkl\",\"rb\"))\n        words=data['text'][args.sequence_length:]\n        MSEs=np.mean(data['MSE'][args.layer][12:17],axis=0)\n    \n    ranked_sentences = rank_sentences(words, MSEs)\n    similar_sents = ranked_sentences[:args.n_sents]\n    divergent_sents = ranked_sentences[-args.n_sents:]\n    print(\"similar sentences:\", similar_sents[:5])\n    print(\"divergent sentences:\", divergent_sents[-5:])\n    \n    ## Save data\n    save_sents(divergent_sents, similar_sents, f\"{args.save_path}formatted_sents_{args.lm_name}_layer{args.layer}_chpt{args.chapter}.pkl\")\n\n\n# ../working/interim_data/lm_embeddings/HP_chpt1_GPT2-xl_base.pkl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:04:46.782747Z","iopub.status.idle":"2025-07-24T01:04:46.782984Z","shell.execute_reply.started":"2025-07-24T01:04:46.782876Z","shell.execute_reply":"2025-07-24T01:04:46.782885Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## TEST","metadata":{}},{"cell_type":"code","source":"f\"../working/interim_data/lm_embeddings/HP_chpt1_{args.lm_name}_base.pkl\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:04:46.783938Z","iopub.status.idle":"2025-07-24T01:04:46.784222Z","shell.execute_reply.started":"2025-07-24T01:04:46.784099Z","shell.execute_reply":"2025-07-24T01:04:46.784110Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for k in data.keys():\n    try:\n        print(k,data[k].shape)\n    except:\n        print(k,len(data[k]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:04:46.785562Z","iopub.status.idle":"2025-07-24T01:04:46.785860Z","shell.execute_reply.started":"2025-07-24T01:04:46.785734Z","shell.execute_reply":"2025-07-24T01:04:46.785747Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"args.sequence_length","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:04:46.787076Z","iopub.status.idle":"2025-07-24T01:04:46.787319Z","shell.execute_reply.started":"2025-07-24T01:04:46.787188Z","shell.execute_reply":"2025-07-24T01:04:46.787196Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data2=pickle.load(open(f\"../working/data_for_analysis/HP_chpt1_{args.lm_name}_base_layer-1.pkl\",\"rb\"))\nfor k in data2.keys():\n    try:\n        print(k,data2[k].shape)\n    except:\n        print(k,len(data2[k]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:04:46.789085Z","iopub.status.idle":"2025-07-24T01:04:46.789341Z","shell.execute_reply.started":"2025-07-24T01:04:46.789203Z","shell.execute_reply":"2025-07-24T01:04:46.789229Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## END OF TEST","metadata":{}},{"cell_type":"markdown","source":"# BEGINING THE ANALYSIS","metadata":{}},{"cell_type":"markdown","source":"### UseFull info\n```python\nword_num = meg_data.shape[0]\nchannel_num = meg_data.shape[1]\ntimepoint_num = meg_data.shape[2]\n\n\ndef single_topoplot(\n    mat,\n    cmap=\"RdBu_r\",\n    vmin=-0.1,\n    vmax=0.1,\n    figsize=(5,5),\n    fontsize=16,\n):\n    \"\"\"Creates single helmet plot for sensor-space MEG data (based on MNE visualization)\n\n    Args:\n        mat (2d numpy array): data to plot of size N sensors x M timepoints\n        cmap (str, optional): colormap name. Defaults to 'RdBu_r'.\n        vmin (float, optional): sets the colorbar min. Defaults to -0.1.\n        vmax (float, optional): sets the colorbar max. Defaults to 0.1.\n        figsize (tuple, optional): figure size. Defaults to (15,15).\n        fontsize (int, optional): font size. Defaults to 16.\n\n    Returns:\n        figure handle\n    \"\"\"\n\ndef topoplot(\n    mat,\n    nrow=4,\n    ncol=5,\n    time_step=25,\n    time_start=0,\n    cmap=\"RdBu_r\",\n    vmin=-0.1,\n    vmax=0.1,\n    figsize=(15, 15),\n    fontsize=16,\n):\n    \"\"\"Creates helmet plots for sensor-space MEG data (based on MNE visualization)\n\n    Args:\n        mat (2d numpy array): data to plot of size N sensors x M timepoints\n        nrow (int, optional): number of rows in plot. Defaults to 4.\n        ncol (int, optional): number of columns in plot. Defaults to 5.\n        time_step (int, optional): time window length. Defaults to 25.\n        time_start (int, optional): what time to start plotting. Defaults to 0.\n        cmap (str, optional): colormap name. Defaults to 'RdBu_r'.\n        vmin (float, optional): sets the colorbar min. Defaults to -0.1.\n        vmax (float, optional): sets the colorbar max. Defaults to 0.1.\n        figsize (tuple, optional): figure size. Defaults to (15,15).\n        fontsize (int, optional): font size. Defaults to 16.\n\n    Returns:\n        figure handle\n    \"\"\"\nprint(\"Ridge regression...\")\nfor tt in range(timepoint_num):\n    brain_responses = meg_data[:,:,tt]\n    embeddings = all_embeddings[args.layer]\n    brain_responses_pred = do_ridge_regression(embeddings, brain_responses)\n\n    all_pred[0, tt] = brain_responses_pred\n\n    for ch, (pred,actual) in enumerate(zip(brain_responses_pred.T, brain_responses.T)):\t# for each channel, all words\n        corr, pvalue = pearsonr(pred,actual,alternative=\"greater\")\n        all_corrs[0, tt, ch] = corr\n        if pvalue < args.p_thresh:\n            all_sig_channels[0, tt, ch] = 1\n\n    sig_channels = all_sig_channels[0, tt]\n    print(f\"layer {args.layer}, {tt*25}-{(tt+1)*25}ms: {np.sum(sig_channels)}\")\n\n    for word, (pred,actual) in enumerate(zip(brain_responses_pred, brain_responses)):\t# for each word, all sig channels\n        all_MSE[0, tt, word] = np.linalg.norm(pred[sig_channels]-actual[sig_channels], ord=2) ** 2 / len(sig_channels)\n        all_cos_sim[0, tt, word] = cosine_similarity(pred[sig_channels],actual[sig_channels])\n\n```\n\nsample rate = 1Khz\n\n{tt*25}-{(tt+1)*25}","metadata":{}},{"cell_type":"markdown","source":"## PART 1 : FINDING BRAIN REGIONS ","metadata":{}},{"cell_type":"code","source":"sig_channels.sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:04:46.791060Z","iopub.status.idle":"2025-07-24T01:04:46.791287Z","shell.execute_reply.started":"2025-07-24T01:04:46.791182Z","shell.execute_reply":"2025-07-24T01:04:46.791191Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(all_MSE.shape)\nprint(brain_responses.shape)\nprint(sig_channels.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:04:46.792289Z","iopub.status.idle":"2025-07-24T01:04:46.792566Z","shell.execute_reply.started":"2025-07-24T01:04:46.792441Z","shell.execute_reply":"2025-07-24T01:04:46.792454Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.mean(all_MSE,axis=1).shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:04:46.793275Z","iopub.status.idle":"2025-07-24T01:04:46.793520Z","shell.execute_reply.started":"2025-07-24T01:04:46.793409Z","shell.execute_reply":"2025-07-24T01:04:46.793418Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(np.mean(all_MSE,axis=1).T)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:04:46.794336Z","iopub.status.idle":"2025-07-24T01:04:46.794615Z","shell.execute_reply.started":"2025-07-24T01:04:46.794475Z","shell.execute_reply":"2025-07-24T01:04:46.794484Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def find_n_largest_values(arr,n=10,row=False):\n    if row:\n        # Get indices of the top-n values in each row (unsorted)\n        indices_unsorted = np.argpartition(-arr, n, axis=1)[:, :n]\n        # Gather the corresponding values\n        row_indices = np.arange(arr.shape[0])[:, None]\n        values_unsorted = arr[row_indices, indices_unsorted]\n        \n        # Optionally sort the top-n values within each row\n        sorted_order = np.argsort(-values_unsorted, axis=1)\n        values_sorted = np.take_along_axis(values_unsorted, sorted_order, axis=1)\n        indices_sorted = np.take_along_axis(indices_unsorted, sorted_order, axis=1)\n        \n        print(f\"Top-{n} values per row:\\n\", values_sorted)\n        print(f\"Indices of top-{n} values per row:\\n\", indices_sorted)\n    else:\n        # Get indices of the top-n values in each column (unsorted)\n        indices_unsorted = np.argpartition(-arr, n, axis=0)[:n, :]\n        # Gather the corresponding values\n        col_indices = np.arange(arr.shape[1])\n        values_unsorted = arr[indices_unsorted, col_indices]\n        \n        # Sort\n        sorted_order = np.argsort(-values_unsorted, axis=0)\n        values_sorted = np.take_along_axis(values_unsorted, sorted_order, axis=0)\n        indices_sorted = np.take_along_axis(indices_unsorted, sorted_order, axis=0)\n        \n        print(f\"Top-{n} values per column:\\n\", values_sorted)\n        print(f\"Indices of top-{n} values per column:\\n\", indices_sorted)\n    return values_sorted,indices_sorted\nfind_n_largest_values(all_MSE[0,:,:],n=10,row=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:04:46.795754Z","iopub.status.idle":"2025-07-24T01:04:46.796037Z","shell.execute_reply.started":"2025-07-24T01:04:46.795864Z","shell.execute_reply":"2025-07-24T01:04:46.795874Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Generate data for analysis HP\nimport os\nimport sys\nimport numpy as np\nimport string\nimport pickle\nimport argparse\n\nimport matplotlib.pyplot as plt\n\nfrom scipy.stats import pearsonr\nfrom scipy.stats import chi2\nfrom scipy.stats import zscore\nimport scipy.io as sio\nfrom scipy.io import loadmat\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\n\nimport statsmodels.api as sm\n\n# from mat4py import loadmat\n\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader, random_split\n\nsys.path.append(\"../\")\n# from dataloader.dataloader import HP_dataset_denoised\n# from utils import meg_sensor_plot\n# from utils import utils\n# from utils.ridge.ridge import bootstrap_ridge\n\nnp.set_printoptions(precision=3,suppress=True)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n\nhome=os.path.expanduser(\"~\")\n\nparser = argparse.ArgumentParser()\n\nparser.add_argument(\"--dataset\", default=\"HP\")\nparser.add_argument(\"--base_data_path\", default=\"../input/divergence-meg-data/\")\nparser.add_argument(\"--chapter\", type=int, default=1)\nparser.add_argument(\"--meg_offset\", type=int, default=0)\nparser.add_argument(\"--p_thresh\", type=float, default=0.001)\n\nparser.add_argument(\"--sequence_length\", type=int, default=20)\nparser.add_argument(\"--lm_name\", default=\"GPT2-xl\")\nparser.add_argument(\"--model_info\", default=\"base\")\nparser.add_argument(\"--layer\", type=int, default=-1)\n\n\n# --- FIX STARTS HERE ---\n# Simulate command-line arguments by passing a list of strings\n\n# Manually construct the list based on the defaults you want to use\nargs_list = [\n    \"--dataset\", \"HP\",\n    \"--base_data_path\", \"../input/divergence-meg-data/\", # Use the path variable\n    \"--chapter\", \"1\",\n    \"--meg_offset\", \"0\",\n    \"--p_thresh\", \"0.001\", # Convert float to string\n\n    \"--sequence_length\", \"20\",\n    \"--lm_name\", \"GPT2-xl\",\n    \"--model_info\", \"base\",\n    \"--layer\", \"-1\"\n]\n\n# Pass the list of arguments to parse_args()\nargs = parser.parse_args(args_list) # <--- The fix is here\n# --- FIX ENDS HERE ---\n\n\nargs.lm_embed_path = f\"../working/interim_data/lm_embeddings/{args.dataset}_chpt{args.chapter}_{args.lm_name}_{args.model_info}.pkl\"\n\nprint(\"Echo arguments:\",args)\n\n## Load MEG data\nwhole_data = HP_dataset_denoised(args)\nmeg_data=whole_data.all_megs[args.sequence_length:]\t# (word, meg_channel, time)\n\n## Load LM embeddings\ndata=pickle.load(open(args.lm_embed_path,\"rb\"))\nall_embeddings=data[\"all_embeddings\"]\t# (layer, word, embedding_dim)\n\nword_num = meg_data.shape[0]\nchannel_num = meg_data.shape[1]\ntimepoint_num = meg_data.shape[2]\nlayer_num = 1\n\n## init arrays\nall_corrs = np.zeros((layer_num, timepoint_num, channel_num))\nall_sig_channels = np.zeros((layer_num, timepoint_num, channel_num), dtype=int)\nall_pred = np.zeros((layer_num, timepoint_num, word_num, channel_num))\nall_MSE = np.zeros((layer_num, timepoint_num, word_num))\nall_cos_sim = np.zeros((layer_num, timepoint_num, word_num))\n\nMSEs_for_channels = np.zeros((timepoint_num, channel_num))  # shape: (timepoints, channels)\ncosine_sim_channels = np.zeros((timepoint_num, channel_num))  # shape: (timepoints, channels)\n    for ch in range(channel_num):\n        preds = brain_responses_pred[:, ch]    # shape: (words,) - predictions for one channel across all words\n        actuals = brain_responses[:, ch]       # shape: (words,) - actuals for one channel across all words\n\n        # MSE for this specific channel across all words\n        mse = np.mean((preds - actuals) ** 2)\n        MSEs_for_channels[tt, ch] = mse\n\n        # Cosine Similarity for this specific channel across all words\n        # Check if norms are non-zero to avoid division by zero in cosine_similarity if any array is all zeros\n        if np.linalg.norm(preds) > 0 and np.linalg.norm(actuals) > 0:\n            # Reshape to (1, -1) for sklearn.metrics.pairwise.cosine_similarity\n            cos_sim = cosine_similarity(preds.reshape(1, -1), actuals.reshape(1, -1))[0, 0]\n        else:\n            cos_sim = 0.0 # Define behavior for all-zero vectors\n\n        cosine_sim_channels[tt, ch] = cos_sim\nfor tt in range(timepoint_num):\n    brain_responses = meg_data[:, :, tt]  # shape: (words, channels)\n    embeddings = all_embeddings[args.layer]  # shape: (words, features)\n    brain_responses_pred = do_ridge_regression(embeddings, brain_responses)  # shape: (words, channels)\n\n    all_pred[0, tt] = brain_responses_pred\n\n    # Pearson correlation per channel\n    for ch in range(channel_num):\n        pred = brain_responses_pred[:, ch]    # shape: (words,)\n        actual = brain_responses[:, ch]       # shape: (words,)\n        corr, pvalue = pearsonr(pred, actual, alternative=\"greater\")\n        all_corrs[0, tt, ch] = corr\n        if pvalue < args.p_thresh:\n            all_sig_channels[0, tt, ch] = 1\n\n    sig_channels = all_sig_channels[0, tt] # sig_channels is (channel_num,) containing 0s or 1s\n    print(f\"layer {args.layer}, {tt*25}-{(tt+1)*25}ms: {np.sum(sig_channels)} significant channels\")\n\n    # Per-word metrics (on significant channels)\n    for word in range(word_num): # Changed 'word' to 'word_idx' to avoid confusion if 'word' is a global\n        pred = brain_responses_pred[word]     # (num_channels,) - all predictions for one word\n        actual = brain_responses[word]        # (num_channels,) - all actuals for one word\n\n        # Ensure there are significant channels for this calculation\n        if np.sum(sig_channels) > 0:\n            # np.linalg.norm(pred[sig_channels] - actual[sig_channels], ord=2)**2 calculates\n            # the sum of squared differences for the selected significant channels for this word.\n            # Dividing by len(sig_channels) makes it the Mean Squared Error (MSE).\n            all_MSE[0, tt, word] = np.linalg.norm(pred[sig_channels == 1] - actual[sig_channels == 1], ord=2) ** 2 / np.sum(sig_channels == 1)\n            # Reshape needed for sklearn.metrics.pairwise.cosine_similarity if inputs are 1D\n            # Ensure not to pass empty arrays if no sig_channels exist for a word\n            if pred[sig_channels == 1].size > 0:\n                 all_cos_sim[0, tt, word] = cosine_similarity(pred[sig_channels == 1].reshape(1, -1), actual[sig_channels == 1].reshape(1, -1))[0, 0]\n            else:\n                 all_cos_sim[0, tt, word] = np.nan # Or 0.0, if desired for no sig channels\n        else:\n            all_MSE[0, tt, word] = np.nan # Or 0.0, if desired for no sig channels\n            all_cos_sim[0, tt, word] = np.nan # Or 0.0, if desired for no sig channels\n\n\n    # --- NEW: Compute per-channel MSE across words ---\n    for ch in range(channel_num):\n        preds = brain_responses_pred[:, ch]    # shape: (words,) - predictions for one channel across all words\n        actuals = brain_responses[:, ch]       # shape: (words,) - actuals for one channel across all words\n\n        # MSE for this specific channel across all words\n        mse = np.mean((preds - actuals) ** 2)\n        MSEs_for_channels[tt, ch] = mse\n\n        # Cosine Similarity for this specific channel across all words\n        # Check if norms are non-zero to avoid division by zero in cosine_similarity if any array is all zeros\n        if np.linalg.norm(preds) > 0 and np.linalg.norm(actuals) > 0:\n            # Reshape to (1, -1) for sklearn.metrics.pairwise.cosine_similarity\n            cos_sim = cosine_similarity(preds.reshape(1, -1), actuals.reshape(1, -1))[0, 0]\n        else:\n            cos_sim = 0.0 # Define behavior for all-zero vectors\n\n        cosine_sim_channels[tt, ch] = cos_sim\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:04:46.798148Z","iopub.status.idle":"2025-07-24T01:04:46.798498Z","shell.execute_reply.started":"2025-07-24T01:04:46.798327Z","shell.execute_reply":"2025-07-24T01:04:46.798343Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"args","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:04:46.799776Z","iopub.status.idle":"2025-07-24T01:04:46.800137Z","shell.execute_reply.started":"2025-07-24T01:04:46.799950Z","shell.execute_reply":"2025-07-24T01:04:46.799967Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"single_topoplot(np.mean(meg_data[0,:,:],axis=1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:04:46.801051Z","iopub.status.idle":"2025-07-24T01:04:46.801402Z","shell.execute_reply.started":"2025-07-24T01:04:46.801221Z","shell.execute_reply":"2025-07-24T01:04:46.801236Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dir()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:04:46.802401Z","iopub.status.idle":"2025-07-24T01:04:46.802746Z","shell.execute_reply.started":"2025-07-24T01:04:46.802563Z","shell.execute_reply":"2025-07-24T01:04:46.802594Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(whole_data.all_texts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:04:46.804742Z","iopub.status.idle":"2025-07-24T01:04:46.805076Z","shell.execute_reply.started":"2025-07-24T01:04:46.804910Z","shell.execute_reply":"2025-07-24T01:04:46.804924Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# END OF WORKING CODE","metadata":{}},{"cell_type":"markdown","source":"# Generate data for analysis Moth","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport numpy as np\nimport string\nimport pickle\nimport argparse\n\nimport matplotlib.pyplot as plt\n\nfrom scipy.stats import pearsonr\nfrom scipy.stats import chi2\nfrom scipy.stats import zscore\nimport scipy.io as sio\nfrom scipy.io import loadmat\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.decomposition import PCA\n\nimport statsmodels.api as sm\n\n# from mat4py import loadmat\n\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader, random_split\n\nsys.path.append(\"../\")\nfrom dataloader.dataloader import HP_dataset_denoised\nfrom utils import meg_sensor_plot\nfrom utils import utils\nfrom utils.ridge.ridge import bootstrap_ridge\n\nnp.set_printoptions(precision=3,suppress=True)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ndef construct_stimuli_and_brain_responses(MEG, word_embeddings, word_onset_point, story_dict, args, layer = -1, PCA_n_components = 50, n_delays = 40, do_zscore = True):\n\t\"\"\"construct stimuli and brain responses for regression\"\"\"\n\t\n\t# construct brain responses\n\tbrain_responses = []\n\tfor story in story_dict:\n\t\tavg_MEG = []\n\t\tfor trial in story_dict[story]:\n\t\t\tif do_zscore:\n\t\t\t\tavg_MEG.append(zscore(MEG[trial]))\n\t\t\telse:\n\t\t\t\tavg_MEG.append(MEG[trial])\n\t\tbrain_responses.append(np.stack(avg_MEG).mean(axis=0))\n\tbrain_responses = np.concatenate(brain_responses, axis = 0)\t# (word, channel)\n\n\tstimuli = np.zeros((brain_responses.shape[0], word_embeddings.shape[2]))\t# (word, embedding_dim)\n\n\t# construct stimuli\n\toffset = 0\n\tidx = 0\n\tfor i, story in enumerate(story_dict):\n\t\ttrial = story_dict[story][0]\n\t\tfor time in word_onset_point[trial][args.sequence_length:]:\n\t\t\tstimuli[time+offset] = word_embeddings[args.layer][idx]\n\t\t\tidx += 1\n\t\toffset += MEG[trial].shape[0]\n\n\t# reduce dimensionality of stimuli\n\tpca = PCA(n_components=PCA_n_components).fit(stimuli)\n\tstimuli = pca.transform(stimuli)\t# (word, PCA_n_components)\n\t\n\t# add delays\n\tstimuli = utils.delay_mat(stimuli, range(n_delays))\t# (word, PCA_n_components*n_delays)\n\n\treturn stimuli, brain_responses\n\nif __name__ == '__main__':\n\thome=os.path.expanduser(\"~\")\n\n\tparser = argparse.ArgumentParser()\n\t\n\tparser.add_argument(\"--dataset\", default=\"Moth\")\n\tparser.add_argument(\"--base_data_path\", default=f\"{home}/Desktop/MEG_divergence/Moth_data/\")\n\tparser.add_argument(\"--p_thresh\", type=int, default=0.001)\n\n\tparser.add_argument(\"--sequence_length\", type=int, default=20)\n\tparser.add_argument(\"--lm_embed_path\", default=f\"{home}/Desktop/MEG_divergence/interim_data/lm_embeddings/Moth_GPT2-xl_base.pkl\")\n\tparser.add_argument(\"--lm_name\", default=\"GPT2-xl\")\n\tparser.add_argument(\"--model_info\", default=\"base\")\n\tparser.add_argument(\"--layer\", type = int, default=-1)\n\n\n\targs = parser.parse_args()\n\n\tprint(\"Echo arguments:\",args)\n\t\n\t## Load data\n\n\tMEG = pickle.load(open(\"../Moth_data/Moth_MEG.pkl\",\"rb\"))\n\tword_onset_point = pickle.load(open(\"../Moth_data/Moth_word_onset_point.pkl\",\"rb\"))\n\tword_embeddings = pickle.load(open(args.lm_embed_path,\"rb\"))[\"all_embeddings\"]\n\tstory_dict = pickle.load(open(\"../Moth_data/Moth_run_info_test_story_dict.pkl\",\"rb\"))\n\n\t# Construct matrix of features\n\n\tall_embeddings, meg_data = construct_stimuli_and_brain_responses(MEG, word_embeddings, word_onset_point, story_dict, args)\n\tall_embeddings = np.expand_dims(all_embeddings, axis=0)\n\tmeg_data = np.expand_dims(meg_data, axis=2)\n\n\tprint(\"embedding shape:\", all_embeddings.shape)\n\tprint(\"meg_data shape:\", meg_data.shape)\n\n\tword_num = meg_data.shape[0]\n\tchannel_num = meg_data.shape[1]\n\ttimepoint_num = 1\n\tlayer_num = 1\n\n\t## init arrays\n\tall_corrs = np.zeros((layer_num, timepoint_num, channel_num))\n\tall_sig_channels = np.zeros((layer_num, timepoint_num, channel_num), dtype=int)\n\tall_pred = np.zeros((layer_num, timepoint_num, word_num, channel_num))\n\tall_MSE = np.zeros((layer_num, timepoint_num, word_num))\n\tall_cos_sim = np.zeros((layer_num, timepoint_num, word_num))\n\n\t## Ridge regression\n\tprint(\"Ridge regression...\")\n\tfor layer in range(layer_num):\n\t\tfor time in range(timepoint_num):\n\t\t\tbrain_responses = meg_data[:,:,time]\n\t\t\tembeddings = all_embeddings[layer]\n\t\t\tbrain_responses_pred = utils.do_ridge_regression(embeddings, brain_responses)\n\n\t\t\tall_pred[layer, time] = brain_responses_pred\n\n\t\t\tfor ch, (pred,actual) in enumerate(zip(brain_responses_pred.T, brain_responses.T)):\t# for each channel, all words\n\t\t\t\tcorr, pvalue = pearsonr(pred,actual,alternative=\"greater\")\n\t\t\t\tall_corrs[layer, time, ch] = corr\n\t\t\t\tif pvalue < args.p_thresh:\n\t\t\t\t\tall_sig_channels[layer, time, ch] = 1\n\n\t\t\tsig_channels = all_sig_channels[layer, time]\n\t\t\tprint(f\"layer {args.layer}: {np.sum(sig_channels)}\")\n\n\t\t\tfor word, (pred,actual) in enumerate(zip(brain_responses_pred, brain_responses)):\t# for each word, all sig channels\n\t\t\t\tall_MSE[layer, time, word] = np.linalg.norm(pred[sig_channels]-actual[sig_channels], ord=2) ** 2 / len(sig_channels)\n\t\t\t\tall_cos_sim[layer, time, word] = utils.cosine_similarity(pred[sig_channels],actual[sig_channels])\n\n\n\tpickle.dump(\n\t\tdict(\n\t\tembedding=all_embeddings,\n\t\tactual=meg_data,\n\t\tpred=all_pred,\n\t\tcorr=all_corrs,\n\t\tMSE=all_MSE,\n\t\tcos=all_cos_sim,\n\t\tsig_channels=all_sig_channels,\n\t\t),\n\t\topen(f\"../interim_data/data_for_analysis/{args.dataset}_{args.lm_name}_{args.model_info}.pkl\",\"wb\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:04:46.806224Z","iopub.status.idle":"2025-07-24T01:04:46.807053Z","shell.execute_reply.started":"2025-07-24T01:04:46.806870Z","shell.execute_reply":"2025-07-24T01:04:46.806888Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Generate LM Embedding Moth","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport numpy as np\nimport string\nimport pickle\nimport argparse\n\nimport matplotlib.pyplot as plt\n\nfrom scipy.stats import pearsonr\nfrom scipy.stats import chi2\nfrom scipy.stats import zscore\nimport scipy.io as sio\nfrom scipy.io import loadmat\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\n\nimport statsmodels.api as sm\n\n# from mat4py import loadmat\n\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader, random_split\n\nsys.path.append(\"../\")\nfrom dataloader.dataloader import HP_dataset_denoised\nfrom utils import meg_sensor_plot\nfrom utils import utils\nfrom utils.ridge.ridge import bootstrap_ridge\n\nnp.set_printoptions(precision=3,suppress=True)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\nif __name__ == '__main__':\n\thome=os.path.expanduser(\"~\")\n\n\tparser = argparse.ArgumentParser()\n\t\n\tparser.add_argument(\"--dataset\", default=\"Moth\")\n\tparser.add_argument(\"--base_data_path\", default=f\"{home}/Desktop/MEG_divergence/Moth_data/\")\n\t# parser.add_argument(\"--chapter\", type=int, default=1)\n\t# parser.add_argument(\"--meg_offset\", type=int, default=0)\n\n\tparser.add_argument(\"--batch_size\", type=int, default=1)\n\tparser.add_argument(\"--sequence_length\", type=int, default=20)\n\tparser.add_argument(\"--lm_name\", default=\"GPT2-xl\")\n\tparser.add_argument(\"--model_info\", default=\"base\")\n\tparser.add_argument(\"--lm_path\")\n\t\n\targs = parser.parse_args()\n\targs.no_cuda=not torch.cuda.is_available()\n\n\tprint(\"Echo arguments:\",args)\n\n\t## Load dataset\n\tMoth_words = pickle.load(open(\"../Moth_data/Moth_words.pkl\",\"rb\"))\n\tMoth_run_info_test_story_dict = pickle.load(open(\"../Moth_data/Moth_run_info_test_story_dict.pkl\",\"rb\"))\n\n\tall_sents = []\n\tfor story in Moth_run_info_test_story_dict:\n\t\tst = Moth_run_info_test_story_dict[story][0]\n\t\tfor i in range(args.sequence_length, len(Moth_words[st])):\n\t\t\tall_sents.append(\" \".join(Moth_words[st][i-args.sequence_length:i]).lower())\n\tprint(\"Number of sentences:\", len(all_sents))\n\n\t## Load LM\n\tif args.model_info==\"base\":\t# if loading base model\n\t\ttokenizer,model=utils.load_tokenizer_and_model_from_transformers(args.lm_name)\n\telse:\t# if loading finetuned model\n\t\tfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\t\tif args.lm_name == \"Llama-2\":\n\t\t\ttokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\", truncation_side=\"left\", padding_side=\"left\")\n\t\telif args.lm_name == \"GPT2-xl\":\n\t\t\ttokenizer = AutoTokenizer.from_pretrained(\"gpt2-xl\", truncation_side=\"left\", padding_side=\"left\")\n\t\telse:\n\t\t\traise ValueError(\"Not a valid lm_name.\")\n\t\tmodel = AutoModelForCausalLM.from_pretrained(args.lm_path, output_hidden_states=True)\n\t\t\n\ttokenizer.pad_token = tokenizer.bos_token\n\n\tif not args.no_cuda:\n\t\tmodel=model.to(\"cuda:0\")\n\tmodel.eval();\n\n\t## Get LM embeddings\n\n\tall_embeddings= []\n\n\tfor i, text in enumerate(all_sents):\n\t\tencodings = tokenizer(text, return_tensors=\"pt\", padding=True)['input_ids']\n\t\t# encodings = tokenizer(batch_text, return_tensors=\"pt\", truncation=True, max_length=args.sequence_length)['input_ids']\n\t\tif not args.no_cuda:\n\t\t\tencodings=encodings.to(\"cuda:0\")\n\n\t\tlast_word = text.split(\" \")[-1]\n\t\tlast_word_pos = utils.find_indices_of_last_word_in_batch(tokenizer,[last_word],encodings)\n\t\tword_start, word_end = last_word_pos[0]\n\n\t\twith torch.no_grad():\n\t\t\toutput=model(encodings)\n\t\t\tembeddings=np.vstack([torch.mean(embed[0, word_start:word_end+1],dim=0).detach().cpu().numpy()  for embed in output['hidden_states']])\n\t\t\tall_embeddings.append(embeddings)\n\n\t\tif i % 100 == 0:\n\t\t\tprint(f\"Finished {i} out of {len(all_sents)}\")\n\n\tall_embeddings=np.stack(all_embeddings,axis=1)\t# (layer, word, embedding_dim)\n\n\tdumped_data=dict(\n\t\t\tall_embeddings=all_embeddings,\n\t\t)\n\n\tpickle.dump(dumped_data,\n\t\topen(f\"{home}/Desktop/MEG_divergence/interim_data/lm_embeddings/{args.dataset}_{args.lm_name}_{args.model_info}.pkl\",\"wb\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T01:04:46.807744Z","iopub.status.idle":"2025-07-24T01:04:46.808077Z","shell.execute_reply.started":"2025-07-24T01:04:46.807908Z","shell.execute_reply":"2025-07-24T01:04:46.807922Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Fine Tune with Commonsense","metadata":{}}]}